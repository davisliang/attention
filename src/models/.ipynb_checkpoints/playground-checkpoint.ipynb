{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "from mxnet import nd, gluon, autograd\n",
    "from mxnet.gluon import nn, Block\n",
    "\n",
    "def one_hots(numerical_list, vocab_size):\n",
    "    result = nd.zeros((len(numerical_list), vocab_size), ctx=ctx)\n",
    "    for i, idx in enumerate(numerical_list):\n",
    "        result[i, idx] = 1.0\n",
    "    return result\n",
    "\n",
    "def textify(embedding):\n",
    "    result = \"\"\n",
    "    indices = nd.argmax(embedding, axis=0).asnumpy()\n",
    "    for idx in indices:\n",
    "        result += character_list[int(idx)]\n",
    "    return result\n",
    "\n",
    "def load_time_machine(seq_length=64, batch_size=1):\n",
    "    # loading dataset\n",
    "    path = \"../../data/timemachine.txt\"\n",
    "    with open(path) as f:\n",
    "        time_machine = f.read()\n",
    "    time_machine = time_machine[:-38083] #hardcoded to remove crap\n",
    "    character_dict, vocab_size = get_char_dict(time_machine)\n",
    "    \n",
    "    time_numerical = [character_dict[char] for char in time_machine]\n",
    "    # -1 here so we have enough characters for labels later\n",
    "    num_samples = (len(time_numerical) - 1) // seq_length\n",
    "    dataset = one_hots(time_numerical[:seq_length*num_samples],vocab_size).reshape((num_samples, seq_length, vocab_size))\n",
    "    num_batches = len(dataset) // batch_size\n",
    "    train_data = dataset[:num_batches*batch_size].reshape((batch_size, num_batches, seq_length, vocab_size))\n",
    "    \n",
    "    # swap batch_size and seq_length axis to make later access easier\n",
    "    train_data = nd.swapaxes(train_data, 0, 1)\n",
    "    train_data = nd.swapaxes(train_data, 1, 2)\n",
    "    print('Shape of data set: ', train_data.shape)\n",
    "    \n",
    "    labels = one_hots(time_numerical[1:seq_length*num_samples+1], vocab_size)\n",
    "    train_label = labels.reshape((batch_size, num_batches, seq_length, vocab_size))\n",
    "    train_label = nd.swapaxes(train_label, 0, 1)\n",
    "    train_label = nd.swapaxes(train_label, 1, 2)\n",
    "    print('Shape of label set: ', train_label.shape)\n",
    "    \n",
    "    return train_data, train_label\n",
    "\n",
    "def get_char_dict(data):\n",
    "    # get character dictionary\n",
    "    character_list = list(set(data))\n",
    "    vocab_size = len(character_list)\n",
    "    # get the character dictionary\n",
    "    character_dict = {}\n",
    "    for e, char in enumerate(character_list):\n",
    "        character_dict[char] = e\n",
    "    return character_dict, vocab_size\n",
    "\n",
    "def get_char_dict_builder(data, character_dict):\n",
    "    # get character dictionary\n",
    "    print \"building dictionary\"\n",
    "    for line in data:\n",
    "        character_list = list(set(line))\n",
    "        # get the character dictionary\n",
    "        for i in range(len(character_list)):\n",
    "            if(character_list[i] not in character_dict):\n",
    "                character_dict[character_list[i]] = len(character_dict)\n",
    "    vocab_size = len(character_dict)\n",
    "    return character_dict, vocab_size\n",
    "\n",
    "def SGD(params, lr):    \n",
    "    for param in params:\n",
    "        param[:] = param - lr * param.grad\n",
    "        \n",
    "\n",
    "def cross_entropy(out, targ):\n",
    "    return - nd.sum(targ * nd.log(out), axis=0, exclude=True)\n",
    "\n",
    "\n",
    "def average_ce_loss(outputs, labels):\n",
    "    assert(len(outputs) == len(labels))\n",
    "    total_loss = 0.\n",
    "    for (output, label) in zip(outputs,labels):\n",
    "        total_loss = total_loss + cross_entropy(output, label)\n",
    "    return total_loss / len(outputs)\n",
    "\n",
    "        \n",
    "def list_to_nd_array(list_of_nd_arrays):\n",
    "    return nd.concat(*list_of_nd_arrays)\n",
    "\n",
    "def list_to_nd_array_with_reshaping(list_of_nd_arrays):\n",
    "    for i in range(len(list_of_nd_arrays)):\n",
    "        list_of_nd_arrays[i]=list_of_nd_arrays[i].reshape((list_of_nd_arrays[i].shape[0],1))\n",
    "    return nd.concat(*list_of_nd_arrays)\n",
    "\n",
    "\n",
    "def translation_numerical(data,character_dict):\n",
    "    print \"turning characters into numerical representation\"\n",
    "    return_list=[]\n",
    "    for line in data:\n",
    "        return_list.append([character_dict[char] for char in line])\n",
    "    return return_list\n",
    "\n",
    "def numerical_to_nd(one_data,translation_dict):\n",
    "    one_hot = one_hots(one_data, len(translation_dict))\n",
    "    temp = one_hot.reshape((1,1,one_hot.shape[0],one_hot.shape[1]))\n",
    "    temp = nd.swapaxes(temp,0,1)\n",
    "    temp = nd.swapaxes(temp,1,2)\n",
    "    return temp\n",
    "\n",
    "def clean_data(train_data, test_data, threshold_min, threshold_max):\n",
    "    print \"cleaning data\"\n",
    "    train_data_list = []\n",
    "    test_data_list = []\n",
    "    for train_line, test_line in zip(train_data,test_data):\n",
    "            train_line = train_line.lower()\n",
    "            test_line = test_line.lower()  \n",
    "            return_train_line = \"\"\n",
    "            return_test_line = \"\"\n",
    "            \n",
    "            for i in range(len(train_line)):\n",
    "                c = train_line[i]\n",
    "                if((ord(c)==32)or(ord(c)>=97 and ord(c)<=122)):\n",
    "                    return_train_line = return_train_line + c\n",
    "                    \n",
    "            for i in range(len(test_line)):\n",
    "                c = test_line[i]\n",
    "                if((ord(c)==32)or(ord(c)>=97 and ord(c)<=122)):\n",
    "                    return_test_line = return_test_line + c\n",
    "            \n",
    "            if(len(return_train_line)>=threshold_min and len(return_train_line)<=threshold_max):\n",
    "                train_data_list.append(return_train_line)\n",
    "                test_data_list.append(return_test_line)\n",
    "    return train_data_list,test_data_list\n",
    "\n",
    "def pad_zeros(data_numerical):\n",
    "    print \"padding zeros\"\n",
    "    #first, find the maximum length of data.\n",
    "    max_len = 0\n",
    "    for line in data_numerical:\n",
    "        if(len(line)>max_len):\n",
    "            max_len = len(line)\n",
    "            \n",
    "    #iterate through each line and pad with zeros until length equals max_len\n",
    "    for i in range(len(data_numerical)):\n",
    "        data_numerical[i] = data_numerical[i] + [0]*(max_len - len(data_numerical[i]))\n",
    "    \n",
    "    return data_numerical           \n",
    "\n",
    "\n",
    "def rnn_helper(num_hidden, num_inputs, num_outputs): \n",
    "    Wxh = nd.random_normal(shape=(num_inputs,num_hidden), ctx=ctx) * .01\n",
    "    Whh = nd.random_normal(shape=(num_hidden,num_hidden), ctx=ctx) * .01\n",
    "    bh = nd.random_normal(shape=num_hidden, ctx=ctx) * .01\n",
    "    Why = nd.random_normal(shape=(num_hidden,num_outputs), ctx=ctx) * .01\n",
    "    by = nd.random_normal(shape=num_outputs, ctx=ctx) * .01\n",
    "    params = [Wxh, Whh, bh, Why, by]\n",
    "\n",
    "    for param in params:\n",
    "        param.attach_grad()\n",
    "    return params\n",
    " \n",
    "def softmax(y_linear):\n",
    "    exp = nd.exp(y_linear-nd.max(y_linear))\n",
    "    partition = nd.nansum(exp, axis=0, exclude=True)\n",
    "    return exp / partition\n",
    "\n",
    "def encoder(steps, input_data, num_hidden, vocab_size, state, params):\n",
    "    Wxh, Whh, bh, Why, by = params\n",
    "    outputs = []\n",
    "    h = state\n",
    "    for i in range(input_data.shape[0]):\n",
    "        input_temp = nd.dot(input_data[i], Wxh)\n",
    "        hidden_temp = nd.dot(h, Whh)\n",
    "        h_linear = input_temp + hidden_temp + bh\n",
    "        h = nd.tanh(h_linear)\n",
    "        yhat_linear = nd.dot(h, Why) + by\n",
    "        outputs.append(nd.expand_dims(yhat_linear[0],axis=1))\n",
    "    return (outputs, h)\n",
    "\n",
    "\n",
    "def attention_helper(num_attention, num_hidden_encoder, num_hidden_decoder):\n",
    "    W = nd.random_normal(shape=(num_attention,num_hidden_decoder), ctx=ctx) * .01\n",
    "    V = nd.random_normal(shape=(num_attention,num_hidden_encoder), ctx=ctx) * .01\n",
    "    w =  nd.random_normal(shape=(1,num_attention), ctx=ctx) * .01\n",
    "    b = nd.random_normal(shape=(num_attention,1), ctx=ctx) * .01\n",
    "    params = [W,V,w,b]\n",
    "    for param in params:\n",
    "        param.attach_grad()\n",
    "    return params\n",
    "\n",
    "def attention(decoder_hidden, encoder_output, att_params):\n",
    "    W, V, w, b = att_params\n",
    "    decoder_temp = nd.dot(W,decoder_hidden)\n",
    "    encoder_temp = nd.dot(V,encoder_output)\n",
    "    net_temp = nd.reshape(decoder_temp,(decoder_temp.shape[0],1))+encoder_temp+b\n",
    "    return nd.dot(w,nd.tanh(net_temp))\n",
    "    #return nd.dot(softmax(nd.dot(decoder_hidden_t, encoder_output)) , encoder_output.T)\n",
    "\n",
    "\n",
    "def decoder(steps, encoder_outputs, state, num_hidden, vocab_size, params, att_params):\n",
    "    Wxh, Whh, bh, Why, by = params\n",
    "    outputs = []\n",
    "    h = state\n",
    "    # only look at steps long. (consider this 'dynamic')\n",
    "    for i in range(steps):\n",
    "        #h=nd.reshape(h,(1,h.size))\n",
    "        attention_temp = attention(h, encoder_outputs, att_params)\n",
    "        input_recursive_temp = nd.dot(nd.sum(attention_temp*encoder_outputs,axis=1), Wxh)\n",
    "        hidden_recursive_temp = nd.dot(h, Whh)\n",
    "        h = nd.tanh(input_recursive_temp + hidden_recursive_temp + bh)\n",
    "        net_temp = nd.dot(h, Why) + by\n",
    "        yhat = nd.softmax(net_temp)\n",
    "        outputs.append(yhat)\n",
    "    return (outputs, h)   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning data\n",
      "building dictionary\n",
      "building dictionary\n",
      "turning characters into numerical representation\n",
      "turning characters into numerical representation\n"
     ]
    }
   ],
   "source": [
    "# open the datasets\n",
    "with open(\"../../data/train.en\",\"rb\") as f:\n",
    "    raw_train_data = f.read().splitlines()\n",
    "with open(\"../../data/train.fr\",\"rb\") as f:\n",
    "    raw_train_labels = f.read().splitlines()\n",
    "\n",
    "#clean data\n",
    "train_data, train_labels = clean_data(raw_train_data, raw_train_labels, 100,150)\n",
    "\n",
    "# create dictionary and a character list \n",
    "translation_dict = {}\n",
    "_, num_items = get_char_dict_builder(train_data,translation_dict)\n",
    "_, num_items = get_char_dict_builder(train_labels, translation_dict)\n",
    "character_list = list(translation_dict.keys())\n",
    "\n",
    "# from characters to numerical representations\n",
    "english_numerical=translation_numerical(train_data,translation_dict)\n",
    "french_numerical=translation_numerical(train_labels,translation_dict)\n",
    "\n",
    "# pad zeros\n",
    "#data = pad_zeros(english_numerical)\n",
    "#labels = pad_zeros(french_numerical)\n",
    "data = english_numerical\n",
    "labels = french_numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ctx = mx.cpu()\n",
    "num_hidden = 256\n",
    "learning_rate = 0.001\n",
    "vocab_size = len(translation_dict)\n",
    "encoder_input_size = vocab_size\n",
    "\n",
    "encoder_params = rnn_helper(num_hidden, num_inputs=27, num_outputs=256)\n",
    "encoder_params_1 = rnn_helper(num_hidden, num_inputs=256, num_outputs=256)\n",
    "decoder_params = rnn_helper(num_hidden, num_inputs=256, num_outputs=27) #num_inputs -> vocab_size\n",
    "att_params = attention_helper(num_hidden, num_hidden_encoder=256, num_hidden_decoder=256)\n",
    "\n",
    "params = decoder_params + encoder_params + att_params +encoder_params_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[ -2.30064361e-05  -4.51234246e-06   3.19543187e-06 ...,  -9.44812655e-06\n",
      "    8.25409643e-06   1.66710379e-05]\n",
      " [  1.03502511e-03   2.01071729e-04  -1.42313176e-04 ...,   4.24035097e-04\n",
      "   -3.70312104e-04  -7.49033410e-04]\n",
      " [ -2.21199560e-04  -4.29479624e-05   3.03964534e-05 ...,  -9.06097121e-05\n",
      "    7.91282582e-05   1.60067153e-04]\n",
      " ..., \n",
      " [ -6.39082049e-04  -1.24176979e-04   8.78900901e-05 ...,  -2.61835754e-04\n",
      "    2.28664212e-04   4.62507480e-04]\n",
      " [ -2.66740739e-04  -5.18753586e-05   3.67182329e-05 ...,  -1.09309716e-04\n",
      "    9.54646748e-05   1.93065032e-04]\n",
      " [ -8.91173200e-04  -1.73131615e-04   1.22538142e-04 ...,  -3.65104119e-04\n",
      "    3.18847800e-04   6.44933025e-04]]\n",
      "<NDArray 256x256 @cpu(0)>\n",
      "\n",
      "[[ -1.91525993e-04   1.04719320e-05  -6.03472381e-06 ...,  -4.59349249e-05\n",
      "    3.32382406e-05   1.07237618e-04]\n",
      " [ -2.27400946e-04  -1.47922265e-05   8.55781309e-06 ...,  -8.12409053e-05\n",
      "    7.03833211e-05   1.52819659e-04]\n",
      " [  2.27156706e-04   1.58749826e-05  -9.07313006e-06 ...,   8.48947093e-05\n",
      "   -7.49054234e-05  -1.55773450e-04]\n",
      " ..., \n",
      " [ -2.35361236e-04  -3.57693352e-05   2.37128497e-05 ...,  -9.24930428e-05\n",
      "    8.08946570e-05   1.67111357e-04]\n",
      " [  2.35052241e-04   3.58046673e-05  -2.40762747e-05 ...,   9.00839441e-05\n",
      "   -7.78432586e-05  -1.64972851e-04]\n",
      " [  2.28797449e-04   2.66976058e-05  -1.90844003e-05 ...,   7.77679379e-05\n",
      "   -6.40006183e-05  -1.51192056e-04]]\n",
      "<NDArray 256x256 @cpu(0)>\n",
      "\n",
      "[  4.67005826e-04   5.87280199e-04  -4.36130620e-04  -5.11696620e-04\n",
      "   4.74288303e-04  -1.96560562e-04   7.62627576e-04   5.04178228e-04\n",
      "  -4.29535634e-04   2.39743968e-04  -7.56297159e-05   1.16862811e-03\n",
      "   3.81158752e-04   4.52296052e-04  -5.57670719e-04  -2.11156323e-04\n",
      "   7.18661468e-04   3.92815971e-04   2.71446863e-03   1.14477974e-04\n",
      "   4.63319680e-04  -3.70849826e-04  -4.79675451e-04  -3.15725309e-04\n",
      "  -4.44933161e-04  -2.44757946e-04  -6.41402090e-04   4.20054886e-04\n",
      "   1.30877699e-04   1.29014312e-04   6.33939868e-04  -1.52533362e-03\n",
      "  -3.86921689e-04  -5.90258860e-04   3.84706364e-04  -5.40526176e-04\n",
      "  -1.83895434e-04  -1.07556907e-03  -6.88652974e-04  -2.83516536e-04\n",
      "  -2.08280908e-04  -3.28318041e-04  -4.84354649e-04   6.90989662e-04\n",
      "   5.97679755e-04   6.29607064e-04   4.36639617e-04  -4.14612528e-04\n",
      "  -4.67146951e-04   4.88503778e-04   5.09916805e-04   3.87724023e-04\n",
      "   7.73839711e-05  -5.32096485e-04  -4.32550500e-04  -8.70141448e-05\n",
      "  -5.81099652e-04  -4.59947478e-04   8.96982907e-04  -9.24216176e-04\n",
      "  -2.78183026e-04   1.72364948e-04   1.52318593e-04  -7.85141136e-04\n",
      "  -4.29731968e-04  -3.20835505e-04   4.03548707e-04  -1.15860358e-03\n",
      "  -5.71989396e-04   4.26796905e-05  -2.08290250e-04  -4.70431027e-04\n",
      "   9.12681222e-04  -1.48647174e-04   4.28336731e-04  -1.68849062e-03\n",
      "   3.61633254e-04  -2.88544979e-04  -5.39000204e-04  -6.08808186e-04\n",
      "   2.87972216e-04   1.63799705e-05  -3.34953889e-04  -4.61464893e-04\n",
      "  -5.07064222e-04   5.74447797e-04   4.08627762e-04   7.53836473e-04\n",
      "  -5.39181812e-04   6.94336253e-04  -2.52402300e-04  -1.69948034e-04\n",
      "   9.01623687e-04  -2.72467965e-04  -2.15808104e-04   8.61442473e-04\n",
      "   4.65722202e-04   4.49571904e-04   3.60862992e-04   3.72460869e-04\n",
      "  -2.48117649e-05   7.79376307e-04   5.04583237e-04   4.67034115e-04\n",
      "   5.61964407e-05   6.00741478e-04   1.16183970e-03  -4.88933991e-04\n",
      "  -1.28227883e-04  -4.75891226e-04  -6.06553804e-04  -9.44727799e-06\n",
      "  -5.36234293e-04  -2.30227219e-04   2.59240129e-04  -4.88603691e-05\n",
      "   7.98365567e-04  -1.56161352e-03  -4.71978827e-04  -5.63546491e-04\n",
      "   8.97131613e-05   5.58467233e-04   3.46649322e-04  -3.85479158e-04\n",
      "  -4.62163880e-04   3.21291736e-07   2.38399385e-04  -1.05812993e-04\n",
      "   3.52060422e-04   1.78376358e-04  -3.55414493e-04   7.98517372e-04\n",
      "   3.66681081e-04  -1.95423025e-04  -3.43235646e-04   2.40476613e-04\n",
      "  -4.83826472e-04   2.93284247e-04  -6.39700913e-04  -2.15539563e-04\n",
      "   4.74594039e-04  -1.45022466e-03   3.46307934e-04  -2.43396062e-04\n",
      "   1.85197918e-04  -6.59631507e-04   1.79582785e-04   3.84232117e-04\n",
      "  -1.48835330e-04   4.95416403e-04  -6.60994439e-04   8.17270426e-04\n",
      "  -3.76067357e-04   4.47107333e-04  -2.80259352e-04   7.18747790e-04\n",
      "  -6.14957244e-04  -2.82097244e-05  -2.20986505e-04   5.04808268e-04\n",
      "  -5.55843755e-04   4.91042912e-04  -4.80583170e-04   5.42480906e-04\n",
      "  -6.56188931e-04  -3.18317965e-04  -3.63535655e-05  -2.72777434e-05\n",
      "  -2.55652587e-04   3.17455415e-05  -3.52176896e-04   4.79283859e-04\n",
      "   1.17891771e-03  -8.51018238e-04  -3.02598310e-05   3.61012673e-04\n",
      "  -6.00950909e-04   4.20823519e-04  -5.54853585e-04   5.19074732e-04\n",
      "  -1.51018467e-04  -2.82486522e-04   8.69106152e-05  -6.64771767e-04\n",
      "  -3.33757023e-04   1.45396349e-04   4.19583463e-04   8.88038834e-04\n",
      "  -5.05931675e-04   5.08108991e-04   6.17443467e-04   8.53963866e-05\n",
      "  -3.59312107e-04   4.37156908e-04   5.76058112e-04  -3.66839929e-04\n",
      "   4.54270543e-04   4.01004218e-04  -8.80104024e-04   7.63241987e-05\n",
      "   1.75841706e-07   3.45383538e-04   4.55880596e-04  -3.99528770e-04\n",
      "  -1.91205239e-04  -2.16805522e-04  -1.50137104e-03   2.47321150e-04\n",
      "   1.45055223e-04  -1.16324009e-04   4.46223596e-04   1.16646104e-03\n",
      "  -1.38225820e-04  -3.32504453e-04   5.97311300e-04  -4.81701980e-04\n",
      "   9.32321418e-04  -3.51953204e-04   3.32172349e-04  -5.08690777e-04\n",
      "  -4.37904091e-04  -5.15496708e-04   5.62308880e-04   2.94535974e-04\n",
      "  -6.95538183e-04  -8.34872015e-04   1.34199800e-05  -1.46061357e-04\n",
      "  -7.46794278e-04   2.20917427e-04   3.85120860e-04  -3.97123862e-04\n",
      "   3.88333981e-04  -4.84537421e-04   4.35701601e-04   1.72453141e-03\n",
      "   3.00533662e-04   7.87442783e-04  -6.18659426e-04   3.77945660e-04\n",
      "   1.10334833e-03  -5.08154684e-04  -5.44708222e-04  -1.67080062e-03\n",
      "  -1.29017353e-04  -5.97324630e-04  -5.76933613e-04   3.98544333e-04\n",
      "  -2.00388976e-03   1.97982867e-04   3.43672291e-04   4.31921042e-04\n",
      "   2.55759689e-04   4.50879917e-04  -4.27114312e-04  -5.84952999e-04]\n",
      "<NDArray 256 @cpu(0)>\n",
      "\n",
      "[[ 0.03865609 -0.01218593  0.01826114 ..., -0.00495211 -0.01243189\n",
      "  -0.00486457]\n",
      " [ 0.04950486 -0.01508312  0.02186081 ..., -0.00584048 -0.01512772\n",
      "  -0.00599245]\n",
      " [-0.05007495  0.01519889 -0.02192052 ...,  0.00587251  0.0152111\n",
      "   0.00603827]\n",
      " ..., \n",
      " [ 0.04947032 -0.0150811   0.02184935 ..., -0.00584253 -0.01512561\n",
      "  -0.00599362]\n",
      " [-0.04877771  0.01491997 -0.02169719 ...,  0.00579269  0.01498989\n",
      "   0.00593072]\n",
      " [-0.04587525  0.0142176  -0.02095061 ...,  0.00559927  0.01437759\n",
      "   0.00565993]]\n",
      "<NDArray 256x27 @cpu(0)>\n",
      "\n",
      "[-0.05132972  0.01592322 -0.02157682  0.01828834 -0.03812295  0.00124953\n",
      "  0.00843241  0.0076763   0.00153181  0.0047174   0.01372184 -0.0281857\n",
      " -0.01285718  0.02691199 -0.00194448 -0.01540785 -0.02658396 -0.02331357\n",
      "  0.03463906  0.01898223  0.00808219  0.01296662  0.01735286  0.00040074\n",
      "  0.00628234  0.01569601  0.00646724]\n",
      "<NDArray 27 @cpu(0)>\n",
      "\n",
      "[[  4.38622301e-05   1.73858716e-05  -3.17075719e-05 ...,   9.69820903e-05\n",
      "   -2.13468393e-05  -8.65694165e-05]\n",
      " [  2.32283073e-05   2.60230227e-05  -2.11656225e-05 ...,   3.60792619e-05\n",
      "   -9.06933838e-06  -3.09836214e-05]\n",
      " [  1.86264958e-06   7.95811684e-06  -4.36770279e-06 ...,   3.95832785e-06\n",
      "    3.52654183e-06  -8.88727664e-06]\n",
      " ..., \n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]]\n",
      "<NDArray 27x256 @cpu(0)>\n",
      "\n",
      "[[ -4.52059612e-06  -5.61027355e-06   3.74041792e-06 ...,  -7.35855383e-06\n",
      "    8.02046031e-07   6.50411039e-06]\n",
      " [ -9.92124711e-08  -4.56566369e-07   2.45945415e-08 ...,   1.17823720e-06\n",
      "   -3.95646055e-07  -1.08640381e-06]\n",
      " [  6.91691582e-07   4.29363268e-07  -2.13547594e-07 ...,   6.67655854e-07\n",
      "   -5.38013467e-07  -5.96303892e-07]\n",
      " ..., \n",
      " [ -2.01923331e-06  -2.04077196e-06   1.13110809e-06 ...,  -3.84465329e-06\n",
      "    9.14469638e-07   3.58002649e-06]\n",
      " [  3.92428092e-07   5.11193605e-07  -5.05354194e-07 ...,   1.23473887e-06\n",
      "   -3.15808393e-07  -1.09738664e-06]\n",
      " [  3.78945606e-06   4.65620042e-06  -3.31081901e-06 ...,   6.98737995e-06\n",
      "   -8.31658383e-07  -6.13874272e-06]]\n",
      "<NDArray 256x256 @cpu(0)>\n",
      "\n",
      "[  2.69161887e-04   3.04023648e-04  -2.11288221e-04   8.31287587e-04\n",
      "   5.46302006e-04   6.09285838e-04   1.06112845e-03   7.82644202e-04\n",
      "   8.83553119e-04   8.76801554e-04  -4.13719717e-05   5.34097955e-04\n",
      "   7.86803139e-04  -7.45026045e-04   2.89101037e-04   3.30332638e-04\n",
      "   2.72352860e-04  -3.97200092e-05   3.56380420e-04   5.52251586e-04\n",
      "   8.24570830e-04   1.69184481e-04   5.41045738e-04   3.67083674e-04\n",
      "   2.39300833e-04  -1.71273408e-04  -7.80363509e-04   6.51454902e-04\n",
      "  -2.61575507e-04   4.78509610e-04   2.17213033e-04  -2.23660463e-04\n",
      "   2.24030184e-04  -5.99340012e-04  -4.47224229e-05  -4.78473492e-04\n",
      "   7.09635089e-04  -2.94422236e-04   6.80156154e-05  -4.48101287e-04\n",
      "   1.60687123e-04   7.43799261e-04  -8.64884467e-04  -1.99563347e-05\n",
      "  -2.45829782e-04   7.24822748e-04  -5.18365123e-04  -5.39638801e-04\n",
      "   3.28709517e-04   7.82228424e-04   3.99375363e-04   3.88976390e-04\n",
      "   6.91530877e-04  -7.98232359e-05   4.59397474e-04   5.38095133e-04\n",
      "   5.47386764e-04   7.82567367e-04  -3.55801603e-06  -1.24741776e-03\n",
      "   1.35402777e-04   8.12890299e-04   8.51844321e-04   6.01181702e-04\n",
      "  -2.70178949e-04   1.66819751e-04  -7.32354471e-04  -2.37403423e-04\n",
      "   1.49999069e-05  -3.41068953e-05  -9.44508705e-04  -1.66711587e-04\n",
      "  -4.14556533e-04   7.92801497e-04  -4.06316482e-04   8.05511256e-04\n",
      "  -2.70638469e-04   4.77337802e-04   5.08640893e-04   2.31988553e-04\n",
      "  -5.56848594e-04  -3.61743325e-04  -3.87325912e-04   8.65447044e-04\n",
      "   5.53571852e-04   4.03362064e-04  -2.31073805e-04  -6.68194320e-04\n",
      "   5.51828765e-04  -3.21036845e-04   2.19510199e-04  -3.64004518e-04\n",
      "  -8.74174293e-04  -2.93358869e-04  -2.60232744e-04  -4.92542167e-04\n",
      "   7.44276564e-04   1.06990279e-03   6.76940603e-04  -7.91698185e-05\n",
      "   8.82908585e-04   1.83267970e-04   4.13133093e-04  -1.90701627e-04\n",
      "  -3.34602402e-04   8.79534520e-04  -5.75174286e-04   7.67917605e-04\n",
      "  -4.84118558e-04  -1.10938691e-03   5.16534899e-04   8.54569196e-04\n",
      "  -2.44607450e-04  -8.84939625e-04   5.95727994e-04   4.78753616e-04\n",
      "   3.72460199e-04   7.41136202e-04   2.15159511e-04  -5.75885409e-04\n",
      "   3.42936575e-04   6.83790131e-04  -6.01868844e-04  -3.85619176e-04\n",
      "  -8.25444236e-04  -3.66970984e-04   4.68002982e-04   5.53754333e-04\n",
      "  -3.14771637e-06  -8.00776528e-04  -2.36392270e-06   1.64464305e-04\n",
      "  -2.76562350e-04  -9.86223924e-04   8.30672798e-05  -2.75996223e-04\n",
      "  -5.87883114e-04  -7.20876153e-04  -3.95616546e-04  -1.43591124e-05\n",
      "   4.99104441e-04  -4.92337800e-04  -6.75218180e-04   1.41364988e-04\n",
      "  -7.79228285e-05   1.81863652e-04  -5.26018150e-04  -2.55993309e-05\n",
      "   5.86111448e-04  -1.45113940e-04   6.94993883e-04   6.38405400e-05\n",
      "  -3.88306536e-04  -3.88089320e-05  -3.72648676e-04   8.67463459e-05\n",
      "  -6.84109458e-04   7.57089991e-04   7.32468383e-04  -1.76808535e-04\n",
      "   4.81458905e-04  -2.91637058e-04   3.91919486e-04   5.40197885e-04\n",
      "   3.95997078e-04   5.46974188e-04  -9.44963715e-04  -1.66079655e-04\n",
      "  -8.24369141e-04   2.09986421e-04   2.35395655e-05   4.51810702e-05\n",
      "  -6.11123745e-04  -4.76753747e-04  -1.75333698e-04   5.55239210e-04\n",
      "  -1.44182239e-04  -3.67603119e-04   1.26327186e-05  -1.70291547e-04\n",
      "  -3.44352651e-04  -7.33626483e-04  -2.53970036e-04   3.02664528e-04\n",
      "   4.40159696e-04   1.58351206e-04  -7.74910324e-04  -2.22572431e-04\n",
      "   8.18823639e-04  -3.13693745e-04  -4.60573239e-04  -1.73654233e-04\n",
      "  -6.77335542e-04   1.49650412e-04  -1.19127872e-04  -3.73136747e-04\n",
      "   2.42217357e-04  -4.75832523e-04   1.68694110e-04  -2.95616570e-04\n",
      "   3.86667845e-04   4.08054708e-04  -6.54499163e-04  -2.86673108e-04\n",
      "   5.90063981e-04  -1.07333239e-04  -1.00400830e-04  -2.29935686e-04\n",
      "  -5.30495658e-04   5.62417670e-04  -3.90609086e-04   2.95477163e-04\n",
      "  -5.49668795e-04  -5.71558077e-04  -9.49444191e-04   1.46771054e-04\n",
      "   3.92040645e-04   3.02545464e-04   6.17249054e-04  -5.68446587e-04\n",
      "   5.68434771e-04  -3.01061431e-04   6.84837229e-04  -5.77592698e-04\n",
      "   3.54219344e-04  -1.68574436e-04   4.87836776e-04  -8.24867224e-04\n",
      "  -4.35701688e-04   5.02606330e-04  -2.69645461e-05  -3.32252093e-04\n",
      "   2.48144730e-04  -2.72639700e-05  -3.38691985e-04   6.74755371e-04\n",
      "  -1.96568828e-04   3.78058496e-04  -4.84313292e-04   2.80931912e-04\n",
      "  -1.40878954e-04  -2.71441531e-04   8.77753773e-05  -4.41748707e-04\n",
      "   2.02497424e-04  -2.34939522e-04  -7.56732887e-04   4.76583809e-04\n",
      "  -7.37909228e-04   4.51385335e-04  -6.33468153e-04   8.27238764e-05\n",
      "   9.85073508e-04   4.56877140e-04  -5.02124531e-05  -3.94656468e-04]\n",
      "<NDArray 256 @cpu(0)>\n",
      "\n",
      "[[ -3.06242036e-05  -2.93992562e-05  -2.14870415e-05 ...,  -1.77796483e-05\n",
      "   -1.70877465e-05  -1.50357046e-05]\n",
      " [  2.66443089e-06   1.83663565e-06   4.06166964e-06 ...,   7.44553290e-08\n",
      "   -4.38651568e-06   5.24996085e-06]\n",
      " [  2.95919267e-06   3.27428847e-06   1.67637529e-06 ...,   8.13504244e-07\n",
      "   -4.05249193e-06  -1.61530461e-05]\n",
      " ..., \n",
      " [ -1.42702966e-05  -1.45507411e-05  -9.08717539e-06 ...,  -4.43556701e-06\n",
      "   -5.23795870e-06   1.01634510e-06]\n",
      " [  4.11210112e-06   4.51790720e-06   5.61276374e-06 ...,  -1.38886105e-06\n",
      "    1.41550925e-06   2.29303600e-06]\n",
      " [  2.79089527e-05   2.86589348e-05   1.98334710e-05 ...,   2.37037057e-05\n",
      "    1.05453446e-05   1.21833873e-05]]\n",
      "<NDArray 256x256 @cpu(0)>\n",
      "\n",
      "[ 0.00176235  0.00176067  0.001258    0.00213716  0.0010737   0.0021132\n",
      "  0.0017406   0.00135565  0.00200797  0.00118207  0.0021713   0.00140058\n",
      "  0.00162697  0.00190041  0.001257    0.00213525  0.00107951  0.00204701\n",
      "  0.00174762  0.00130405  0.00201707  0.00112898  0.00215743  0.00148692\n",
      "  0.00149726  0.00191826  0.00127313  0.00215023  0.0011684   0.00183187\n",
      "  0.00175362  0.0012783   0.00208968  0.00108398  0.00210606  0.00170158\n",
      "  0.001373    0.00195273  0.00121827  0.00220892  0.0013533   0.00166124\n",
      "  0.00190848  0.00125587  0.00211258  0.00105079  0.002037    0.00171724\n",
      "  0.00129382  0.00199617  0.00113124  0.0021811   0.00146144  0.00150775\n",
      "  0.00187588  0.00128903  0.00216947  0.0011352   0.00192479  0.00176302\n",
      "  0.00131552  0.00207474  0.00111136  0.00209288  0.00164576  0.00139673\n",
      "  0.00190954  0.00123211  0.00218873  0.00127763  0.00171221  0.00186712\n",
      "  0.00126074  0.00217762  0.00105489  0.00207348  0.00173201  0.00132098\n",
      "  0.00200691  0.00115573  0.00218664  0.00147034  0.00155448  0.00188505\n",
      "  0.00125344  0.00215527  0.00112848  0.00196713  0.00173486  0.00132538\n",
      "  0.00205038  0.00113879  0.0021133   0.00162884  0.00145837  0.00193531\n",
      "  0.0012635   0.00221215  0.00126303  0.00177712  0.00185639  0.00127023\n",
      "  0.00217436  0.00106086  0.00211659  0.00172294  0.00136606  0.00203091\n",
      "  0.00120535  0.00223227  0.00148222  0.00158247  0.00194273  0.00126875\n",
      "  0.00215379  0.00114035  0.00197422  0.001729    0.00130674  0.00199092\n",
      "  0.00112401  0.00211017  0.00152185  0.00143139  0.00191651  0.00123397\n",
      "  0.00213969  0.00121197  0.00179129  0.00178961  0.00125446  0.00211755\n",
      "  0.00106093  0.00204694  0.00168662  0.00131677  0.00195047  0.0011531\n",
      "  0.00212921  0.00137457  0.00158523  0.00185219  0.00122599  0.00208031\n",
      "  0.0010528   0.0020315   0.00173443  0.00130118  0.00201414  0.00113005\n",
      "  0.00217307  0.00149705  0.00148895  0.00190668  0.00127491  0.00216539\n",
      "  0.00117605  0.00186595  0.0017862   0.00130051  0.00212672  0.00109944\n",
      "  0.00210706  0.00170288  0.0013842   0.00196912  0.00122376  0.00220687\n",
      "  0.00135307  0.0016658   0.00191312  0.00126863  0.00214166  0.00106481\n",
      "  0.00208393  0.00175762  0.00131532  0.00202731  0.00114685  0.00220579\n",
      "  0.00147723  0.00152449  0.00189703  0.00130012  0.00218469  0.00114284\n",
      "  0.00192742  0.00176522  0.00132101  0.00208416  0.00112088  0.00214937\n",
      "  0.00168972  0.00142827  0.00195259  0.00126277  0.00225086  0.00131356\n",
      "  0.0017473   0.0019055   0.00128296  0.00221459  0.00107268  0.00211618\n",
      "  0.00176773  0.00133561  0.00202734  0.00116593  0.00220183  0.00148052\n",
      "  0.00154953  0.00187944  0.00124776  0.00214473  0.00112332  0.00193607\n",
      "  0.00170743  0.0013034   0.00201606  0.00111906  0.00206671  0.00159306\n",
      "  0.00141674  0.00187928  0.00123236  0.00216509  0.00123619  0.00175164\n",
      "  0.00182936  0.00126136  0.00216575  0.0010558   0.00209693  0.00170692\n",
      "  0.0013309   0.00197657  0.0011716   0.00216266  0.00143714  0.00152868\n",
      "  0.00187642  0.00122454  0.00207564  0.00110068  0.00192457  0.00168503\n",
      "  0.00125256  0.001903    0.00102659  0.00186528  0.0014382   0.00105757\n",
      "  0.00157107  0.00134191  0.0005522   0.00106034]\n",
      "<NDArray 256 @cpu(0)>\n",
      "\n",
      "[[  3.79481862e-05   6.88944347e-05  -7.12207984e-05 ...,   8.34150123e-05\n",
      "   -8.21346039e-05  -7.17801959e-05]\n",
      " [  3.36845915e-05   5.71502533e-05  -5.88697803e-05 ...,   6.74497714e-05\n",
      "   -6.64519976e-05  -5.87418144e-05]\n",
      " [  1.56294227e-05   2.75526891e-05  -2.84401249e-05 ...,   3.30003531e-05\n",
      "   -3.25013025e-05  -2.85407496e-05]\n",
      " ..., \n",
      " [ -4.46387021e-05  -7.78829053e-05   8.03455696e-05 ...,  -9.29272501e-05\n",
      "    9.15318524e-05   8.05210293e-05]\n",
      " [  1.07031992e-04   1.97083864e-04  -2.03852454e-04 ...,   2.39971967e-04\n",
      "   -2.36293185e-04  -2.06084704e-04]\n",
      " [  9.57985831e-05   1.86421486e-04  -1.93297979e-04 ...,   2.31529295e-04\n",
      "   -2.27934026e-04  -1.97220943e-04]]\n",
      "<NDArray 256x256 @cpu(0)>\n",
      "\n",
      "[[ -4.23312514e-07   1.85924182e-05  -3.96789483e-06 ...,  -1.14856448e-05\n",
      "   -4.80479866e-06  -1.60096970e-05]\n",
      " [ -3.07883198e-07   1.35223345e-05  -2.88586511e-06 ...,  -8.35355786e-06\n",
      "   -3.49455877e-06  -1.16439151e-05]\n",
      " [ -1.60385781e-07   7.04452259e-06  -1.50340770e-06 ...,  -4.35181983e-06\n",
      "   -1.82049700e-06  -6.06595040e-06]\n",
      " ..., \n",
      " [  4.44546970e-07  -1.95249813e-05   4.16692001e-06 ...,   1.20617497e-05\n",
      "    5.04580476e-06   1.68127208e-05]\n",
      " [ -1.24365260e-06   5.46243718e-05  -1.16576575e-05 ...,  -3.37447054e-05\n",
      "   -1.41163928e-05  -4.70363520e-05]\n",
      " [ -1.28801707e-06   5.65730697e-05  -1.20735285e-05 ...,  -3.49485344e-05\n",
      "   -1.46199882e-05  -4.87143479e-05]]\n",
      "<NDArray 256x256 @cpu(0)>\n",
      "\n",
      "[[ 0.0119098   0.00647366  0.00941507 -0.00669074 -0.00860461 -0.00905931\n",
      "  -0.00995294 -0.0103841   0.00957103 -0.01354099 -0.0104276   0.00702531\n",
      "   0.01499818  0.00839966 -0.00798193 -0.01089888  0.01107127  0.01043149\n",
      "   0.0163897  -0.00954112 -0.01198683 -0.01444501 -0.0128438   0.01465375\n",
      "   0.00959346 -0.01119385 -0.0125577   0.01076888  0.00782789  0.01767931\n",
      "  -0.01211414 -0.01090439 -0.01645572  0.00915634 -0.01101137 -0.01007294\n",
      "   0.01225725  0.01261707  0.01119708  0.011951   -0.00955839  0.01287679\n",
      "   0.01336027  0.01014581 -0.01096057 -0.01273426 -0.00933426 -0.00681871\n",
      "   0.0129606  -0.01412254  0.00921244  0.01137445  0.01661274  0.01303595\n",
      "   0.002974    0.01154693  0.01209914 -0.00771491 -0.01186409 -0.01175654\n",
      "  -0.01276084  0.01515238  0.01115805 -0.01288151 -0.01492513  0.01212811\n",
      "  -0.00936074  0.01620346  0.00794872 -0.01113256  0.01480939 -0.00871986\n",
      "   0.01668542  0.00613985  0.01236008  0.00356821  0.00789463 -0.01597314\n",
      "   0.01028743  0.00839441 -0.01074035  0.01305834 -0.00983559 -0.00847449\n",
      "   0.0095883  -0.01624467 -0.01359068  0.01418483  0.0101914   0.01268051\n",
      "   0.00896353 -0.01346013 -0.0139184  -0.01445881 -0.01211912  0.01378868\n",
      "  -0.01480279 -0.0134327  -0.01186705  0.01147335  0.01369575  0.01002877\n",
      "   0.01228751  0.01180219 -0.01430801 -0.00552511 -0.01084363  0.00949553\n",
      "  -0.01091405 -0.01331631 -0.00830002 -0.01113763 -0.0157603   0.0150298\n",
      "  -0.01586956  0.01318749  0.01192633  0.00832957 -0.0134055  -0.01018796\n",
      "   0.01395042 -0.0111237   0.01082023 -0.01275672 -0.01332498  0.01151171\n",
      "  -0.00968812  0.00775165 -0.00817932 -0.01230107 -0.00941661 -0.00454819\n",
      "  -0.01213445 -0.00529522 -0.01139204 -0.01176289  0.0052595   0.00369107\n",
      "  -0.01654326  0.01578952  0.0127763   0.01260166  0.01364291 -0.01302808\n",
      "   0.01123497 -0.01503177  0.01596264 -0.01090716 -0.00976476 -0.01015121\n",
      "   0.01217176  0.00985111 -0.01042082 -0.01024711 -0.01301978  0.01410107\n",
      "   0.01164964 -0.01211018  0.00369518 -0.01201591  0.01243115  0.01590883\n",
      "   0.01237341 -0.00762699  0.01025883  0.01374793 -0.01102339  0.0115297\n",
      "   0.01437082  0.0135265  -0.00661323 -0.00757849  0.01002834 -0.00402089\n",
      "  -0.01612531  0.01350787  0.01215806 -0.01138597 -0.0108526  -0.01199557\n",
      "   0.01230542  0.00993335  0.00888257 -0.01452006 -0.01466323 -0.00833416\n",
      "   0.00795504  0.0081402  -0.00029377  0.00972643  0.01289847  0.00640527\n",
      "  -0.01087742 -0.01161503 -0.00421815  0.00972729  0.0055891   0.01239304\n",
      "  -0.01273716  0.0112243  -0.01721455  0.01553119 -0.01260606  0.01474774\n",
      "   0.01146593 -0.012913   -0.0118283   0.01195293 -0.00658135 -0.00957782\n",
      "   0.00902474  0.01015255  0.00840835 -0.01290899  0.01148786  0.015072\n",
      "  -0.01234009  0.00940521  0.00882428 -0.01570937  0.01400371 -0.01500719\n",
      "   0.01315443  0.01052039  0.00467685  0.01374871  0.00073382  0.01205705\n",
      "  -0.01592612  0.00948063 -0.00463441 -0.01291209  0.01010187 -0.01322797\n",
      "   0.01094608  0.01074496  0.00153479  0.01195704  0.01234654 -0.01090015\n",
      "   0.01751078 -0.01370541  0.01411068 -0.01043195 -0.01175355 -0.01831014\n",
      "  -0.00946035 -0.00630277 -0.01056656  0.01226384 -0.0109187  -0.00947527\n",
      "   0.00928159 -0.00826809  0.01368941  0.01596301]]\n",
      "<NDArray 1x256 @cpu(0)>\n",
      "\n",
      "[[ -5.01286704e-04]\n",
      " [ -3.64587118e-04]\n",
      " [ -1.89934231e-04]\n",
      " [  1.88680994e-03]\n",
      " [  1.28529151e-03]\n",
      " [  3.34928831e-04]\n",
      " [  9.17134457e-04]\n",
      " [  2.84374412e-03]\n",
      " [ -2.25960300e-03]\n",
      " [  1.47786399e-03]\n",
      " [  1.49722863e-03]\n",
      " [ -4.60454234e-04]\n",
      " [ -6.00024476e-04]\n",
      " [ -3.40124301e-04]\n",
      " [  2.92973185e-04]\n",
      " [  6.19585742e-04]\n",
      " [ -6.38393511e-04]\n",
      " [ -7.46074831e-04]\n",
      " [ -2.34731007e-03]\n",
      " [  1.29239145e-03]\n",
      " [  1.00189866e-03]\n",
      " [  4.02354868e-04]\n",
      " [  2.41686217e-03]\n",
      " [ -1.32584979e-03]\n",
      " [ -7.46768084e-04]\n",
      " [  2.78348045e-04]\n",
      " [  1.29074964e-03]\n",
      " [ -5.83889370e-04]\n",
      " [ -1.30581064e-03]\n",
      " [ -7.15803006e-04]\n",
      " [  1.58291357e-03]\n",
      " [  4.87402285e-04]\n",
      " [  5.79447136e-04]\n",
      " [ -5.65718336e-04]\n",
      " [  3.07747367e-04]\n",
      " [  3.74544761e-04]\n",
      " [ -1.18097663e-03]\n",
      " [ -2.19417783e-03]\n",
      " [ -1.97265856e-03]\n",
      " [ -1.69624062e-03]\n",
      " [  6.81203674e-04]\n",
      " [ -1.81276293e-03]\n",
      " [ -4.31147753e-04]\n",
      " [ -1.26151450e-03]\n",
      " [  2.31576239e-04]\n",
      " [  6.25713612e-04]\n",
      " [  3.46513203e-04]\n",
      " [  1.09794689e-03]\n",
      " [ -1.41647609e-03]\n",
      " [  1.72200566e-03]\n",
      " [ -6.83937804e-04]\n",
      " [ -1.75438588e-03]\n",
      " [ -2.39926646e-03]\n",
      " [ -2.23871088e-03]\n",
      " [  5.34535411e-06]\n",
      " [ -2.61890190e-03]\n",
      " [ -2.44906754e-04]\n",
      " [  1.07392296e-03]\n",
      " [  4.43009194e-04]\n",
      " [  1.03712548e-03]\n",
      " [  1.54318393e-03]\n",
      " [ -7.61331234e-04]\n",
      " [ -2.57247966e-03]\n",
      " [  9.62681079e-04]\n",
      " [  8.54573562e-04]\n",
      " [ -4.50424384e-04]\n",
      " [  7.75177148e-04]\n",
      " [ -8.64689355e-04]\n",
      " [ -1.12557621e-03]\n",
      " [  1.58898416e-03]\n",
      " [ -1.64717925e-03]\n",
      " [  9.24862514e-04]\n",
      " [ -1.64270401e-03]\n",
      " [ -1.59552158e-03]\n",
      " [ -1.69167906e-04]\n",
      " [ -1.06614556e-04]\n",
      " [ -2.23166589e-03]\n",
      " [  5.41287416e-04]\n",
      " [ -8.22463189e-05]\n",
      " [ -2.98844255e-03]\n",
      " [  9.10913979e-04]\n",
      " [ -1.73005485e-03]\n",
      " [  6.27296744e-04]\n",
      " [  1.39345904e-03]\n",
      " [ -1.27743668e-04]\n",
      " [  6.65875734e-04]\n",
      " [  1.20137038e-03]\n",
      " [ -2.18700478e-03]\n",
      " [ -3.34088458e-04]\n",
      " [ -2.12290627e-03]\n",
      " [ -2.28702230e-03]\n",
      " [  8.24336195e-04]\n",
      " [  5.19008434e-04]\n",
      " [  1.77855231e-03]\n",
      " [  1.68194086e-03]\n",
      " [ -6.83775521e-04]\n",
      " [  7.99936010e-04]\n",
      " [  2.31110584e-03]\n",
      " [  3.85766994e-04]\n",
      " [ -1.58819661e-03]\n",
      " [ -3.05784197e-04]\n",
      " [ -6.27688947e-04]\n",
      " [ -1.72316947e-03]\n",
      " [ -7.08299107e-04]\n",
      " [  1.03530637e-03]\n",
      " [  1.23614422e-03]\n",
      " [  7.93482293e-04]\n",
      " [ -1.39001303e-03]\n",
      " [  1.50004867e-04]\n",
      " [  8.60715052e-04]\n",
      " [  1.10407406e-03]\n",
      " [  5.65288065e-04]\n",
      " [  2.49018054e-03]\n",
      " [ -1.29583711e-03]\n",
      " [  5.19502675e-04]\n",
      " [ -1.30345696e-03]\n",
      " [ -2.48034345e-03]\n",
      " [ -1.02775788e-03]\n",
      " [  1.57844403e-03]\n",
      " [  8.89447692e-05]\n",
      " [ -9.89465043e-04]\n",
      " [  1.10765116e-03]\n",
      " [ -3.45048378e-04]\n",
      " [  9.00217332e-04]\n",
      " [  9.74067138e-04]\n",
      " [ -1.54210534e-03]\n",
      " [  1.56798481e-03]\n",
      " [ -7.11391680e-04]\n",
      " [  5.87564195e-04]\n",
      " [  1.35436491e-03]\n",
      " [  6.26032474e-04]\n",
      " [  8.10377096e-05]\n",
      " [  5.74206992e-04]\n",
      " [  1.31271861e-03]\n",
      " [  1.90922827e-03]\n",
      " [  6.89608918e-04]\n",
      " [ -1.96136127e-04]\n",
      " [  4.02878941e-05]\n",
      " [  2.80388631e-03]\n",
      " [ -1.65852252e-03]\n",
      " [ -1.49512640e-03]\n",
      " [ -8.89638730e-04]\n",
      " [ -2.26034271e-03]\n",
      " [  2.12768954e-03]\n",
      " [ -8.05767486e-04]\n",
      " [  1.19154714e-03]\n",
      " [ -1.11357227e-03]\n",
      " [  1.59334973e-03]\n",
      " [  1.83295866e-03]\n",
      " [  1.27096486e-03]\n",
      " [ -3.19063687e-03]\n",
      " [ -1.02499477e-03]\n",
      " [  1.27409806e-03]\n",
      " [  9.66540712e-04]\n",
      " [  1.01134263e-03]\n",
      " [ -5.22179354e-04]\n",
      " [ -8.61507899e-04]\n",
      " [  6.53836178e-04]\n",
      " [ -4.00381441e-06]\n",
      " [  1.37662655e-03]\n",
      " [ -7.71529740e-04]\n",
      " [ -1.47032947e-03]\n",
      " [ -6.21073530e-04]\n",
      " [  1.39811845e-03]\n",
      " [ -3.55642429e-03]\n",
      " [ -6.88533124e-04]\n",
      " [  1.01518678e-03]\n",
      " [ -7.27501116e-04]\n",
      " [ -6.44000829e-04]\n",
      " [ -8.96016194e-04]\n",
      " [  1.52836042e-03]\n",
      " [  1.28531491e-03]\n",
      " [ -3.54144198e-04]\n",
      " [  4.16627037e-04]\n",
      " [  6.74855430e-04]\n",
      " [ -2.15617678e-04]\n",
      " [ -1.35577074e-03]\n",
      " [  1.62790576e-03]\n",
      " [  2.89659365e-04]\n",
      " [  1.33693800e-03]\n",
      " [ -4.18801676e-04]\n",
      " [ -1.15696480e-03]\n",
      " [ -3.30858806e-04]\n",
      " [  3.05202254e-03]\n",
      " [  2.13826960e-03]\n",
      " [  1.63552829e-03]\n",
      " [ -3.31698079e-03]\n",
      " [ -3.71815055e-04]\n",
      " [  2.43049431e-06]\n",
      " [ -6.16739970e-04]\n",
      " [ -9.36648692e-04]\n",
      " [ -3.83846549e-04]\n",
      " [  4.28947911e-04]\n",
      " [  1.39528187e-03]\n",
      " [  2.41976755e-04]\n",
      " [ -2.57305149e-03]\n",
      " [ -1.04094204e-03]\n",
      " [ -3.68593755e-04]\n",
      " [  4.94223845e-04]\n",
      " [ -1.37218949e-03]\n",
      " [  1.12378155e-03]\n",
      " [ -1.26654305e-03]\n",
      " [  1.14681956e-03]\n",
      " [ -3.37458262e-03]\n",
      " [ -3.70907655e-04]\n",
      " [  1.60002557e-03]\n",
      " [  2.47820280e-03]\n",
      " [ -1.30490656e-03]\n",
      " [  1.09482068e-03]\n",
      " [  6.49745925e-04]\n",
      " [ -5.53524587e-04]\n",
      " [ -1.38349354e-03]\n",
      " [ -1.28276367e-03]\n",
      " [  6.29253802e-04]\n",
      " [ -1.88222434e-03]\n",
      " [ -1.15616433e-03]\n",
      " [  4.92081977e-04]\n",
      " [ -1.00886181e-03]\n",
      " [ -2.58150464e-03]\n",
      " [  3.26654845e-04]\n",
      " [ -3.71767906e-04]\n",
      " [  7.43871205e-04]\n",
      " [ -5.88633236e-04]\n",
      " [ -2.27598147e-03]\n",
      " [ -1.20242330e-04]\n",
      " [ -1.26113673e-03]\n",
      " [  6.98667209e-05]\n",
      " [ -2.36376974e-04]\n",
      " [  1.55769498e-03]\n",
      " [ -2.20019440e-03]\n",
      " [  8.51175810e-06]\n",
      " [  9.96222021e-04]\n",
      " [ -1.00234943e-03]\n",
      " [  7.64094875e-04]\n",
      " [ -1.72558369e-03]\n",
      " [ -7.01008481e-04]\n",
      " [ -1.05056060e-04]\n",
      " [ -7.55927293e-04]\n",
      " [ -2.21443921e-03]\n",
      " [  4.32364235e-04]\n",
      " [ -1.16205751e-03]\n",
      " [  2.68065324e-03]\n",
      " [ -5.87493414e-04]\n",
      " [  1.13110873e-03]\n",
      " [  1.08224561e-03]\n",
      " [  6.38719299e-04]\n",
      " [  4.37018403e-04]\n",
      " [  8.66764894e-05]\n",
      " [  6.72909024e-04]\n",
      " [ -1.75913377e-03]\n",
      " [  9.15913493e-04]\n",
      " [  1.65634369e-03]\n",
      " [ -1.22744168e-04]\n",
      " [  5.26430493e-04]\n",
      " [ -1.47278234e-03]\n",
      " [ -1.52532221e-03]]\n",
      "<NDArray 256x1 @cpu(0)>\n",
      "\n",
      "[[  4.22482044e-05   3.31030315e-05  -4.64743316e-05 ...,  -1.86700127e-05\n",
      "    1.70162639e-05   1.12821799e-05]\n",
      " [  4.04409511e-05   3.18274033e-05  -4.44423058e-05 ...,  -1.82914682e-05\n",
      "    1.66941772e-05   1.10731471e-05]\n",
      " [  4.34319845e-05   3.36529483e-05  -4.76629539e-05 ...,  -2.00527084e-05\n",
      "    1.81833093e-05   1.24109556e-05]\n",
      " ..., \n",
      " [  4.43596255e-05   4.21111545e-05  -4.87381367e-05 ...,  -1.47598357e-05\n",
      "    1.45778122e-05   3.64284460e-06]\n",
      " [  4.12693153e-05   3.90376154e-05  -4.53651410e-05 ...,  -1.37275192e-05\n",
      "    1.35398814e-05   3.48719550e-06]\n",
      " [  3.95867319e-05   3.78223776e-05  -4.35867514e-05 ...,  -1.25287306e-05\n",
      "    1.24819544e-05   2.68395979e-06]]\n",
      "<NDArray 256x256 @cpu(0)>\n",
      "\n",
      "[[ -2.06481869e-04  -1.69863226e-04   2.16098779e-04 ...,   1.63530043e-04\n",
      "   -1.49477128e-04  -1.03856692e-04]\n",
      " [ -5.98344668e-05  -5.02209878e-05   6.24984532e-05 ...,   4.78186485e-05\n",
      "   -4.38764946e-05  -2.98635696e-05]\n",
      " [  2.18532543e-04   1.80521922e-04  -2.30601858e-04 ...,  -1.58694107e-04\n",
      "    1.45382975e-04   9.86898376e-05]\n",
      " ..., \n",
      " [  1.55895104e-04   1.27877138e-04  -1.62930883e-04 ...,  -1.26079351e-04\n",
      "    1.15255170e-04   8.08683471e-05]\n",
      " [ -1.86030025e-04  -1.53972069e-04   1.95329718e-04 ...,   1.42498771e-04\n",
      "   -1.30526983e-04  -8.95280464e-05]\n",
      " [ -1.46550854e-04  -1.21074285e-04   1.53136571e-04 ...,   1.18395234e-04\n",
      "   -1.08426771e-04  -7.55154324e-05]]\n",
      "<NDArray 256x256 @cpu(0)>\n",
      "\n",
      "[ -7.42641743e-03  -6.10314216e-03   7.80462893e-03   6.70888752e-04\n",
      "  -5.53257763e-03  -2.68172752e-03   6.62373239e-03   4.43204446e-03\n",
      "   2.81151920e-03   4.20302898e-03  -6.35873154e-03  -3.78418551e-03\n",
      "   4.53394186e-03  -4.94745467e-03  -6.23810571e-03  -9.54811927e-03\n",
      "   3.62317357e-03  -4.62516258e-03  -1.33893092e-03  -7.34048290e-03\n",
      "  -5.89983817e-03  -9.06866230e-03  -6.32902840e-03   4.81752492e-03\n",
      "   7.45501369e-03  -3.34170461e-03  -7.81393424e-03  -5.03543625e-03\n",
      "  -5.90411760e-03  -7.42322998e-03  -7.76361488e-03  -7.61727715e-05\n",
      "   5.73830120e-03   5.29077789e-03   5.11759613e-03  -5.94503805e-03\n",
      "   6.43883180e-03  -4.27247351e-03   7.64524378e-03  -3.20962165e-03\n",
      "  -8.48750398e-03  -6.38996623e-03   3.57457716e-03   7.76354643e-03\n",
      "   6.87739719e-03  -2.48411275e-03  -6.37514144e-03  -6.93950662e-03\n",
      "   4.35522012e-03   6.98848069e-03  -7.69020757e-03   2.15197611e-03\n",
      "   5.09397686e-03   3.56414448e-03  -5.99256530e-03   3.85967339e-03\n",
      "  -6.89823227e-03  -5.84729016e-03  -5.52331051e-03   5.66726923e-03\n",
      "  -7.70745054e-03   6.12393674e-03  -1.72909920e-03   7.40716420e-03\n",
      "   5.96558850e-04   4.05361550e-03  -4.49893158e-03  -2.41875532e-03\n",
      "  -8.26791767e-03   5.72840543e-03  -6.74622552e-03   3.99127090e-03\n",
      "  -6.75107213e-03   3.43641895e-03  -2.81165517e-03  -4.26384108e-03\n",
      "  -4.55808220e-03   4.77495650e-03   6.65743602e-03   6.96677528e-03\n",
      "  -6.02982938e-03  -4.08312073e-03  -3.78856272e-03  -7.54464930e-03\n",
      "   6.62804116e-03  -5.06059872e-03   8.72986391e-03   4.24949313e-03\n",
      "  -7.10089644e-03   3.79192200e-03   5.30606927e-03   2.42152554e-03\n",
      "  -4.50304430e-03  -6.58138236e-03  -9.62858927e-03  -7.79126771e-03\n",
      "   1.05313845e-02  -5.94759639e-03   6.75308425e-03   5.61163388e-03\n",
      "  -8.46288446e-03  -9.15931421e-04   9.21193510e-03  -4.60382691e-03\n",
      "   4.11824510e-03  -4.83874604e-03  -5.92385326e-03  -4.25532460e-03\n",
      "  -3.75843770e-03  -5.23615908e-03   6.62437314e-03   3.65445507e-03\n",
      "   3.11134267e-03  -6.23234827e-03   4.36399039e-03   1.01303523e-02\n",
      "  -3.52364406e-03   4.77700494e-03   6.26009470e-03  -6.83256891e-03\n",
      "   4.89863381e-03  -4.50495537e-03  -2.26202887e-03  -7.19586667e-03\n",
      "  -6.21721800e-03   6.16709935e-03   7.36909872e-03  -7.29719736e-03\n",
      "  -8.05819687e-03   7.78272748e-03   4.35755635e-03   4.72694123e-03\n",
      "   5.15601225e-03  -6.04626210e-03  -7.40521401e-03   3.44240502e-03\n",
      "  -6.92520617e-03   4.64728335e-03  -6.72428124e-03   6.86854590e-03\n",
      "   4.97536687e-03   6.42777653e-03   5.48416423e-03   8.43609497e-03\n",
      "   9.72048752e-03   4.30909637e-03  -6.49182079e-03  -2.65907613e-03\n",
      "   3.54912714e-03   5.28943818e-03   2.52216612e-03   6.76076673e-03\n",
      "  -4.24451334e-03  -6.83319010e-03  -3.56197736e-04  -6.29568426e-03\n",
      "  -8.63708276e-03  -4.12919698e-03  -6.20451849e-03  -4.87687858e-03\n",
      "   7.02580111e-03   2.69074203e-03  -7.83441588e-03  -7.73283234e-03\n",
      "   5.71283326e-03  -5.19930897e-03   6.56620134e-03   4.62714164e-03\n",
      "   5.89253567e-03  -4.67955554e-03  -6.30835444e-03  -1.30760972e-03\n",
      "  -6.49656355e-03   1.42743147e-03  -4.81432956e-03   4.44710115e-03\n",
      "  -6.41754875e-03   5.90024656e-03   1.12609891e-02   8.99394508e-03\n",
      "  -6.77656382e-03   6.89999014e-03   5.47388243e-03   5.41643891e-03\n",
      "   2.58461921e-03   9.28366836e-03   4.37896186e-03   3.66475829e-03\n",
      "  -1.04612047e-02   6.51739864e-03   6.54065050e-03   8.96821637e-03\n",
      "   1.01888413e-02   4.41346131e-03  -5.34381764e-03  -7.23717641e-03\n",
      "  -7.56299589e-03  -6.40879339e-03  -4.24841186e-03  -2.29785731e-03\n",
      "   5.94943715e-03   5.53438999e-03  -3.87518597e-03   3.81897995e-03\n",
      "   5.95037360e-03   5.49021317e-03   3.74100800e-03  -7.20793381e-03\n",
      "  -4.32608183e-03  -8.51036049e-03  -3.45867872e-03   5.29363658e-03\n",
      "  -4.06853436e-03  -7.29487929e-03  -4.74858657e-03   5.84164122e-03\n",
      "  -8.33267532e-03  -6.72010705e-03  -6.27439562e-03   9.73922201e-03\n",
      "  -2.06497405e-03  -5.45529090e-03  -5.41359186e-03   4.73346934e-03\n",
      "   7.88904447e-03  -8.30553472e-03  -7.17191864e-03  -7.80365523e-03\n",
      "  -6.36746455e-03   3.98611277e-03   9.17523913e-03   5.08014206e-03\n",
      "   8.96946900e-03  -6.62183715e-03  -7.95168336e-03  -3.20764049e-03\n",
      "   5.17427269e-03   4.51512076e-03  -8.22471641e-03   6.51385542e-03\n",
      "   4.94839065e-03  -7.75410049e-03   3.82839376e-03  -5.80721768e-03\n",
      "  -8.12797621e-03  -5.57755586e-03  -6.69195922e-03  -6.08163234e-03\n",
      "   6.87320577e-03  -4.94698621e-03  -8.24062247e-03  -5.14356513e-03\n",
      "   2.21770769e-03   5.62670175e-03  -5.14399121e-03  -3.54226888e-03]\n",
      "<NDArray 256 @cpu(0)>\n",
      "\n",
      "[[  3.03008477e-04   5.10312311e-05  -6.53704046e-04 ...,  -1.57475748e-04\n",
      "   -2.38990368e-04  -1.62328419e-04]\n",
      " [  8.87702336e-05   1.50049073e-05  -1.91501866e-04 ...,  -4.61712807e-05\n",
      "   -7.00141754e-05  -4.75896049e-05]\n",
      " [ -3.05853871e-04  -5.13463347e-05   6.59871730e-04 ...,   1.58844807e-04\n",
      "    2.41238347e-04   1.63753139e-04]\n",
      " ..., \n",
      " [ -2.28855308e-04  -3.87048021e-05   4.93697298e-04 ...,   1.19045610e-04\n",
      "    1.80499861e-04   1.22700774e-04]\n",
      " [  2.66466930e-04   4.48978972e-05  -5.74866077e-04 ...,  -1.38498595e-04\n",
      "   -2.10168655e-04  -1.42764853e-04]\n",
      " [  2.12853149e-04   3.60477861e-05  -4.59168135e-04 ...,  -1.10754729e-04\n",
      "   -1.67877821e-04  -1.14151298e-04]]\n",
      "<NDArray 256x256 @cpu(0)>\n",
      "\n",
      "[ 0.01046837  0.00175554 -0.02258561 -0.01419095 -0.00951135 -0.01109147\n",
      "  0.01367111 -0.01037538 -0.01478509 -0.00328743 -0.00556911  0.0036243\n",
      "  0.00233552  0.00233464 -0.00100241 -0.00796224  0.01161843  0.0103641\n",
      " -0.0034789   0.02168995  0.02248804  0.0018411   0.00623679 -0.02258087\n",
      "  0.00792949  0.02084206 -0.00029623 -0.01455426 -0.00458201  0.01180925\n",
      "  0.0267249  -0.00203354 -0.00447273  0.0019864  -0.00581984 -0.00053553\n",
      "  0.00696653 -0.00141664 -0.0004896   0.00104386  0.00912015 -0.00471764\n",
      "  0.00299195 -0.01139414  0.00236834 -0.00487485 -0.01888022  0.00538012\n",
      "  0.00487808  0.0118336  -0.00475468  0.01525989  0.0100026   0.01668941\n",
      " -0.01328571 -0.00770467  0.00167919 -0.00751579 -0.01517922 -0.00408358\n",
      " -0.02056286  0.00171223  0.00355654  0.00819102 -0.00823477 -0.00923318\n",
      "  0.00521208  0.00198261 -0.00154142  0.01329736  0.00136043 -0.00963501\n",
      "  0.01828567  0.000956    0.01602155  0.01559459 -0.01595633 -0.00397818\n",
      "  0.00805013 -0.0049347  -0.01134525 -0.02519979  0.00017433 -0.01018561\n",
      " -0.0058865   0.01211313  0.01152496 -0.00380936  0.01498659 -0.01414324\n",
      "  0.00844547  0.002948    0.0067329   0.00655278 -0.00303263 -0.01335741\n",
      " -0.01207358 -0.00911668  0.00163448  0.01088478  0.00608897  0.01267396\n",
      "  0.00911966 -0.016228   -0.0103754   0.00321721 -0.0013884   0.01763481\n",
      " -0.00600722  0.00328438  0.00137145 -0.00012401  0.00987867  0.00913161\n",
      " -0.0044101  -0.015146   -0.00280852 -0.00377415 -0.0014577  -0.00089609\n",
      "  0.01817525 -0.01243381  0.00685349 -0.01325041 -0.01166241  0.00024591\n",
      "  0.00438275  0.02132726 -0.00620277 -0.01093489 -0.0038395   0.00831998\n",
      "  0.01109327  0.00868132 -0.00820403  0.01163681 -0.00085533 -0.00051678\n",
      "  0.00692416  0.00546554 -0.00354505  0.00974319 -0.01059296  0.00295335\n",
      "  0.0009569   0.00414621  0.01675181 -0.00794009 -0.00463991  0.0001962\n",
      "  0.01009426  0.00309033 -0.01346875  0.01494596  0.01242381 -0.00586062\n",
      " -0.01823189 -0.00070861  0.00657919  0.00475163  0.0101314   0.01540505\n",
      " -0.00212947  0.0104009  -0.01455726 -0.00829284 -0.01275052 -0.00790195\n",
      " -0.01379973  0.00403804 -0.00111961  0.00855193  0.01034045  0.00232126\n",
      " -0.0132074  -0.00167484  0.00919372 -0.00480573  0.00766697 -0.00283559\n",
      "  0.01390524 -0.0052705   0.0119749  -0.00716151 -0.00327103 -0.01229313\n",
      " -0.00145247 -0.01197154 -0.00843404 -0.0132364   0.01320995  0.00478719\n",
      "  0.00212765  0.00422505 -0.00466678  0.01927604 -0.00184048 -0.00175408\n",
      " -0.00086701 -0.00432501 -0.00331268 -0.00624326  0.00373866 -0.01626999\n",
      " -0.01969004  0.00462487  0.00421917 -0.00774074  0.00860638 -0.006103\n",
      " -0.01165534  0.00623602  0.0018495   0.00805973  0.00751562  0.0227277\n",
      " -0.01477596 -0.01088871 -0.00119786 -0.00267651  0.00174064 -0.01556384\n",
      "  0.01932958  0.01117107 -0.01690817  0.00495071 -0.00212532 -0.0032001\n",
      " -0.00582481  0.01030493  0.01454163  0.01145587 -0.00284179 -0.00887264\n",
      " -0.01341637 -0.01414534 -0.00309803  0.00481497 -0.01024478  0.01030475\n",
      " -0.01081167 -0.00362916 -0.0150535  -0.00455386 -0.00288675 -0.00672853\n",
      " -0.01393766 -0.00087296 -0.00389152 -0.00755243 -0.01622501 -0.01907427\n",
      "  0.0042104  -0.00543549 -0.00825684 -0.0056036 ]\n",
      "<NDArray 256 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(params)):\n",
    "    print params[i].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('pred text: ', '                                                                                                                                                                               ')\n",
      "('cumulative loss: ', 0.02859285831451416)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-363-ef75316d3e14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage_ce_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_decoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0madam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msqrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/davis/anaconda2/lib/python2.7/site-packages/mxnet/ndarray/ndarray.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, out_grad, retain_graph, train_mode)\u001b[0m\n\u001b[1;32m   2000\u001b[0m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2001\u001b[0m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2002\u001b[0;31m             ctypes.c_void_p(0)))\n\u001b[0m\u001b[1;32m   2003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2004\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtostype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi']= 120\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss_tracker = []\n",
    "counter = 0\n",
    "vs, sqrs = setup_adam(params)\n",
    "for epoch in range(100):\n",
    "    cum_loss = 0\n",
    "    for i in range(len(data)):\n",
    "        \n",
    "        with autograd.record():\n",
    "            en = numerical_to_nd(data[i],translation_dict)\n",
    "            fr = numerical_to_nd(labels[i],translation_dict)\n",
    "            en = en.reshape((en.shape[1],en.shape[2],en.shape[3]))\n",
    "            fr = fr.reshape((fr.shape[1],fr.shape[2],fr.shape[3]))\n",
    "            \n",
    "            output_encoder_layer_0,hidden_encoder_layer_0=encoder(\n",
    "                en.shape[0], en, num_hidden, int(en.shape[2]), \n",
    "                nd.zeros(num_hidden),encoder_params)\n",
    "            \n",
    "            temp = nd.concat(*output_encoder_layer_0)\n",
    "            o_e = nd.reshape(temp,(temp.shape[1],1,temp.shape[0]))\n",
    "            \n",
    "            output_encoder_layer_1,hidden_encoder_layer_1=encoder(\n",
    "                o_e.shape[0], o_e, num_hidden, int(o_e.shape[2]), \n",
    "                hidden_encoder_layer_0,encoder_params_1)\n",
    "       \n",
    "            out_enc = list_to_nd_array(output_encoder_layer_1)\n",
    "        \n",
    "            output_decoder, hidden_state = decoder(\n",
    "                fr.shape[0],out_enc,nd.reshape(hidden_encoder_layer_1,(num_hidden)),\n",
    "                num_hidden,int(fr.shape[2]),decoder_params, att_params)\n",
    "            \n",
    "            loss = average_ce_loss(output_decoder, nd.reshape(fr,(fr.shape[0],fr.shape[2]))) \n",
    "\n",
    "        loss.backward()\n",
    "        counter += 1\n",
    "        adam(params, vs, sqrs, learning_rate, 1, counter)\n",
    "        \n",
    "        #graphing\n",
    "        sum_loss = nd.sum(loss)\n",
    "        cum_loss += sum_loss.asscalar()\n",
    "        x_axis = range(len(loss_tracker))\n",
    "        if(i%100==0):\n",
    "            \n",
    "            print(\"pred text: \",textify(list_to_nd_array_with_reshaping(output_decoder)))\n",
    "            print(\"cumulative loss: \", cum_loss/100)\n",
    "            cum_loss = 0\n",
    "            loss_tracker.append(cum_loss)\n",
    "    \n",
    "    plt.semilogy(x_axis, loss_tracker)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def setup_adam(params):\n",
    "    sqrs = []\n",
    "    vs = []\n",
    "    for param in params:\n",
    "        vs.append(param.zeros_like())\n",
    "        sqrs.append(param.zeros_like())\n",
    "    return vs, sqrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class attention_block(Block):\n",
    "    def __init__(self, decoder_state_size, encoder_state_size, attention_size, **kwargs):\n",
    "        super(attention_block, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.decoder_state_size = decoder_state_size\n",
    "            self.encoder_state_size = encoder_state_size\n",
    "            self.attention_size = attention_size\n",
    "            \n",
    "            self.W = self.params.get('W', init=mx.init.Xavier(magnitude=2.24), \n",
    "                                     shape=(self.attention_size,self.decoder_state_size))\n",
    "            self.V = self.params.get('V', init=mx.init.Xavier(magnitude=2.24), \n",
    "                                     shape=(self.attention_size,self.encoder_state_size))\n",
    "            self.w = self.params.get('w', init=mx.init.Xavier(magnitude=2.24), \n",
    "                                     shape=(1,self.attention_size))\n",
    "            self.b = self.params.get('b', shape=(self.attention_size,1))\n",
    "    \n",
    "    def forward(self, decoder_hidden, encoder_output):\n",
    "        with encoder_output.context:\n",
    "            decoder_temp = nd.dot(self.W,decoder_hidden)\n",
    "            encoder_temp = nd.dot(self.V,encoder_output)\n",
    "            net_temp = nd.reshape(decoder_temp,(decoder_temp.shape[0],1))+encoder_temp+self.b\n",
    "            return nd.dot(self.w,nd.tanh(net_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
       " [ 0.  0.  0. ...,  0.  0.  0.]\n",
       " [ 0.  0.  0. ...,  0.  0.  0.]\n",
       " ..., \n",
       " [ 0.  0.  0. ...,  0.  0.  0.]\n",
       " [ 0.  0.  0. ...,  0.  0.  0.]\n",
       " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
       "<NDArray 256x256 @cpu(0)>"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[17].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[  1.30422052e-03  -6.41440973e-03   5.10825589e-03 ...,  -1.34379510e-02\n",
       "    4.31262924e-05   9.32443980e-03]\n",
       " [  1.39874090e-02   1.74041204e-02   1.10777542e-02 ...,   6.40203105e-03\n",
       "    2.06707995e-02   7.28362380e-03]\n",
       " [  1.37236156e-03   5.07817464e-03   2.42010169e-02 ...,  -7.58874975e-03\n",
       "   -8.40481278e-03   8.14634562e-03]\n",
       " ..., \n",
       " [ -1.86159983e-02  -1.86261116e-03   3.53552550e-02 ...,  -1.22878852e-03\n",
       "    3.85040039e-04  -1.27779124e-02]\n",
       " [  1.55838989e-02  -1.56477792e-03  -1.03876069e-02 ...,  -6.73914840e-03\n",
       "    1.66862477e-02  -2.55577289e-03]\n",
       " [  1.31259812e-03   9.93658323e-03  -5.96137485e-03 ...,  -1.68684535e-02\n",
       "    1.60950851e-02  -2.09686020e-03]]\n",
       "<NDArray 256x256 @cpu(0)>"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet.gluon import nn, rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes exactly 5 arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-213-fae25bbca6bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m27\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBasicAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdense\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m27\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_units\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes exactly 5 arguments (1 given)"
     ]
    }
   ],
   "source": [
    "e = rnn.LSTM(256, 3, input_size=27)\n",
    "d = rnn.LSTM(256, 3, input_size = 256)\n",
    "\n",
    "dense = nn.Dense(27, in_units = 256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
