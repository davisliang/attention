{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "\n",
    "from os.path import expanduser\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "GLOBAL_VOCAB_SIZE = 257\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(filename):\n",
    "    relative_path = \"../../data/\"\n",
    "    data = open(expanduser(relative_path+filename),\"rb\")\n",
    "    data_list = []\n",
    "    for line in data:\n",
    "        data_list.append(np.asarray(list(line)))\n",
    "    return np.asarray(data_list)\n",
    "\n",
    "def preprocess_data(data):\n",
    "    newdata = []\n",
    "    for row in data:\n",
    "        newrow = np.zeros(row.shape)\n",
    "        for i in range(len(row)):\n",
    "            newrow[i]=ord(row[i])\n",
    "        newdata.append(newrow)\n",
    "    return np.array(newdata)\n",
    "\n",
    "def encoder(hidden_size, input_data):\n",
    "    encoder_cell = tf.nn.rnn_cell.BasicLSTMCell(hidden_size)\n",
    "    initial_state = rnn_cell.zero_state(batch_size, dtype=tf.float32)\n",
    "    outputs, state = tf.nn.dynamic_rnn(encoder_cell, input_data, initial_state = initial_state, dtype=tf.float32)\n",
    "    return outputs, state\n",
    "\n",
    "def decoder(hidden_size, input_data):\n",
    "    decoder_cell = tf.nn.rnn_cell.BasicLSTMCell(hidden_size)\n",
    "    helper = tf.contrib.seq2seq.TrainingHelper(input_data, decoder_lengths)\n",
    "    initial_state = rnn_cell.zero_state(batch_size, dtype=tf.float32)\n",
    "    outputs, state = tf.nn.dynamic_rnn(decoder_cell, input_data, initial_state = initial_state, dtype=tf.float32)\n",
    "    return outputs\n",
    "\n",
    "def sentence_to_one_hot(sentence_numpy_array):\n",
    "    one_hot_data = np.zeros((len(sentence_numpy_array),GLOBAL_VOCAB_SIZE))\n",
    "    for i in range(len(sentence_numpy_array)):\n",
    "        one_hot_data[i][int(sentence_numpy_array[i])]=1\n",
    "    return one_hot_data\n",
    "\n",
    "def data_to_one_hot(data):\n",
    "    data_list = []\n",
    "    for sentence in data:\n",
    "        data_list.append(sentence_to_one_hot(sentence))\n",
    "    return data_list\n",
    "    # return one hot vectors for each input character\n",
    "\n",
    "def generate_decoder_target(numpy_sequence):\n",
    "    #EOS at the end\n",
    "    seq_reshaped=numpy_sequence.reshape((1,numpy_sequence.shape[0],numpy_sequence.shape[1]))\n",
    "    EOS = np.zeros((1,1,257))\n",
    "    EOS[0,0,256] = 1\n",
    "    return np.append(x,EOS,axis=1)\n",
    "\n",
    "def generate_decoder_input(numpy_sequence):\n",
    "    #EOS at the beginning\n",
    "    seq_reshaped=numpy_sequence.reshape((1,numpy_sequence.shape[0],numpy_sequence.shape[1]))\n",
    "    EOS = np.zeros((1,1,257))\n",
    "    EOS[0,0,256] = 1\n",
    "    return np.append(EOS,x,axis=1)\n",
    "\n",
    "def generate_encoder_input(numpy_sequence):\n",
    "    return numpy_sequence.reshape((1,numpy_sequence.shape[0],numpy_sequence.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Prepare Data\n",
    "\"\"\"\n",
    "\n",
    "#extract data\n",
    "train_english = extract_data(\"train.10k.en\")\n",
    "train_german = extract_data(\"train.10k.de\")\n",
    "valid_english = extract_data(\"valid.100.en\")\n",
    "valid_german = extract_data(\"valid.100.de\")\n",
    "\n",
    "#preprocess data\n",
    "train_english_processed = preprocess_data(train_english)\n",
    "train_german_processed = preprocess_data(train_german)\n",
    "valid_english_processed = preprocess_data(valid_english)\n",
    "valid_german_processed = preprocess_data(valid_german)\n",
    "\n",
    "#data to one hot\n",
    "one_hot_train_english = data_to_one_hot(train_english_processed)\n",
    "one_hot_train_german = data_to_one_hot(train_german_processed)\n",
    "one_hot_valid_english = data_to_one_hot(valid_english_processed)\n",
    "one_hot_valid_german = data_to_one_hot(valid_german_processed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs and outputs\n",
    "\n",
    "tf.reset_default_graph() \n",
    "sess = tf.InteractiveSession() \n",
    "\n",
    "batch_size = 1\n",
    "max_sequence_length = 10\n",
    "encoder_inputs = tf.placeholder(shape=(batch_size, None, GLOBAL_VOCAB_SIZE), dtype=tf.float32, name='encoder_inputs')\n",
    "decoder_inputs = tf.placeholder(shape=(batch_size, None, GLOBAL_VOCAB_SIZE), dtype=tf.float32, name='decoder_inputs')\n",
    "decoder_targets = tf.placeholder(shape=(batch_size, None, GLOBAL_VOCAB_SIZE), dtype=tf.float32, name='decoder_targets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder network\n",
    "hidden_size = 100\n",
    "batch_size = 100\n",
    "with tf.variable_scope('encoder'):\n",
    "    encoder_cell = tf.nn.rnn_cell.BasicLSTMCell(hidden_size)\n",
    "    (encoder_output, encoder_final_state) = tf.nn.dynamic_rnn(encoder_cell, encoder_inputs, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoder network\n",
    "with tf.variable_scope('decoder'):\n",
    "    decoder_cell = tf.nn.rnn_cell.BasicLSTMCell(hidden_size)\n",
    "    (decoder_output, decoder_final_state) = tf.nn.dynamic_rnn(decoder_cell, decoder_inputs, initial_state = encoder_final_state, dtype=tf.float32)\n",
    "\n",
    "decoder_logits = tf.contrib.layers.linear(decoder_output, GLOBAL_VOCAB_SIZE)\n",
    "decoder_prediction = tf.argmax(decoder_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer\n",
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=decoder_targets,\n",
    "    logits=decoder_logits,\n",
    ")\n",
    "\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.5460315, None]\n",
      "[5.5352378, None]\n",
      "[5.5243373, None]\n",
      "[5.5131769, None]\n",
      "[5.4999194, None]\n",
      "[5.485013, None]\n",
      "[5.4650874, None]\n",
      "[5.4386644, None]\n",
      "[5.3996711, None]\n",
      "[5.3394704, None]\n",
      "[5.2291522, None]\n",
      "[5.0429311, None]\n",
      "[4.7993741, None]\n",
      "[4.5448742, None]\n",
      "[4.3222103, None]\n",
      "[4.1335917, None]\n",
      "[3.9647334, None]\n",
      "[3.8142729, None]\n",
      "[3.677259, None]\n",
      "[3.5515034, None]\n",
      "[3.4368556, None]\n",
      "[3.332624, None]\n",
      "[3.2397745, None]\n",
      "[3.1576931, None]\n",
      "[3.0869825, None]\n",
      "[3.0265203, None]\n",
      "[2.9758241, None]\n",
      "[2.9331725, None]\n",
      "[2.8978794, None]\n",
      "[2.868588, None]\n",
      "[2.8440888, None]\n",
      "[2.8231077, None]\n",
      "[2.8048377, None]\n",
      "[2.7888064, None]\n",
      "[2.7743282, None]\n",
      "[2.7614083, None]\n",
      "[2.7498317, None]\n",
      "[2.7396758, None]\n",
      "[2.7306972, None]\n",
      "[2.7228506, None]\n",
      "[2.7159379, None]\n",
      "[2.7098794, None]\n",
      "[2.7048867, None]\n",
      "[2.7008262, None]\n",
      "[2.6976159, None]\n",
      "[2.6948125, None]\n",
      "[2.6923368, None]\n",
      "[2.6898978, None]\n",
      "[2.6873362, None]\n",
      "[2.6849968, None]\n",
      "[2.6816788, None]\n",
      "[2.6788681, None]\n",
      "[2.6758132, None]\n",
      "[2.6733165, None]\n",
      "[2.6698627, None]\n",
      "[2.6668596, None]\n",
      "[2.6650534, None]\n",
      "[2.6637545, None]\n",
      "[2.6625466, None]\n",
      "[2.6600735, None]\n",
      "[2.6572478, None]\n",
      "[2.6551139, None]\n",
      "[2.65362, None]\n",
      "[2.6520145, None]\n",
      "[2.652545, None]\n",
      "[2.6496384, None]\n",
      "[2.6482556, None]\n",
      "[2.6464553, None]\n",
      "[2.6460896, None]\n",
      "[2.6426082, None]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-bc9160dc1f65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mencoder_inputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgenerate_encoder_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mdecoder_inputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgenerate_decoder_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mdecoder_targets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgenerate_decoder_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         })\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/davisl/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/davisl/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/davisl/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/davisl/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/davisl/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# start session\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "data_train = one_hot_train_english\n",
    "data_labels = one_hot_train_german\n",
    "\n",
    "for i in range(len(data_train)):\n",
    "    input_sequence = data_train[i]\n",
    "    output_sequence = data_labels[i]\n",
    "\n",
    "    loss_ = sess.run([loss, train_op],\n",
    "        feed_dict={\n",
    "            encoder_inputs: generate_encoder_input(input_sequence),\n",
    "            decoder_inputs: generate_decoder_input(output_sequence),\n",
    "            decoder_targets: generate_decoder_target(output_sequence),\n",
    "        })\n",
    "    \n",
    "    print loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
