{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "from mxnet import nd, gluon, autograd\n",
    "from mxnet.gluon import nn, Block\n",
    "\n",
    "def one_hots(numerical_list, vocab_size):\n",
    "    result = nd.zeros((len(numerical_list), vocab_size), ctx=ctx)\n",
    "    for i, idx in enumerate(numerical_list):\n",
    "        result[i, idx] = 1.0\n",
    "    return result\n",
    "\n",
    "def textify(embedding):\n",
    "    result = \"\"\n",
    "    indices = nd.argmax(embedding, axis=0).asnumpy()\n",
    "    for idx in indices:\n",
    "        result += character_list[int(idx)]\n",
    "    return result\n",
    "\n",
    "def load_time_machine(seq_length=64, batch_size=1):\n",
    "    # loading dataset\n",
    "    path = \"../../data/timemachine.txt\"\n",
    "    with open(path) as f:\n",
    "        time_machine = f.read()\n",
    "    time_machine = time_machine[:-38083] #hardcoded to remove crap\n",
    "    character_dict, vocab_size = get_char_dict(time_machine)\n",
    "    \n",
    "    time_numerical = [character_dict[char] for char in time_machine]\n",
    "    # -1 here so we have enough characters for labels later\n",
    "    num_samples = (len(time_numerical) - 1) // seq_length\n",
    "    dataset = one_hots(time_numerical[:seq_length*num_samples],vocab_size).reshape((num_samples, seq_length, vocab_size))\n",
    "    num_batches = len(dataset) // batch_size\n",
    "    train_data = dataset[:num_batches*batch_size].reshape((batch_size, num_batches, seq_length, vocab_size))\n",
    "    \n",
    "    # swap batch_size and seq_length axis to make later access easier\n",
    "    train_data = nd.swapaxes(train_data, 0, 1)\n",
    "    train_data = nd.swapaxes(train_data, 1, 2)\n",
    "    print('Shape of data set: ', train_data.shape)\n",
    "    \n",
    "    labels = one_hots(time_numerical[1:seq_length*num_samples+1], vocab_size)\n",
    "    train_label = labels.reshape((batch_size, num_batches, seq_length, vocab_size))\n",
    "    train_label = nd.swapaxes(train_label, 0, 1)\n",
    "    train_label = nd.swapaxes(train_label, 1, 2)\n",
    "    print('Shape of label set: ', train_label.shape)\n",
    "    \n",
    "    return train_data, train_label\n",
    "\n",
    "def get_char_dict(data):\n",
    "    # get character dictionary\n",
    "    character_list = list(set(data))\n",
    "    vocab_size = len(character_list)\n",
    "    # get the character dictionary\n",
    "    character_dict = {}\n",
    "    for e, char in enumerate(character_list):\n",
    "        character_dict[char] = e\n",
    "    return character_dict, vocab_size\n",
    "\n",
    "def get_char_dict_builder(data, character_dict):\n",
    "    # get character dictionary\n",
    "    print \"building dictionary\"\n",
    "    for line in data:\n",
    "        character_list = list(set(line))\n",
    "        # get the character dictionary\n",
    "        for i in range(len(character_list)):\n",
    "            if(character_list[i] not in character_dict):\n",
    "                character_dict[character_list[i]] = len(character_dict)\n",
    "    vocab_size = len(character_dict)\n",
    "    return character_dict, vocab_size\n",
    "\n",
    "def SGD(params, lr):    \n",
    "    for param in params:\n",
    "        param[:] = param - lr * param.grad\n",
    "        \n",
    "\n",
    "def cross_entropy(out, targ):\n",
    "    return - nd.sum(targ * nd.log(out), axis=0, exclude=True)\n",
    "\n",
    "\n",
    "def average_ce_loss(outputs, labels):\n",
    "    assert(len(outputs) == len(labels))\n",
    "    total_loss = 0.\n",
    "    for (output, label) in zip(outputs,labels):\n",
    "        total_loss = total_loss + cross_entropy(output, label)\n",
    "    return total_loss / len(outputs)\n",
    "\n",
    "        \n",
    "def list_to_nd_array(list_of_nd_arrays):\n",
    "    return nd.concat(*list_of_nd_arrays)\n",
    "\n",
    "def list_to_nd_array_with_reshaping(list_of_nd_arrays):\n",
    "    for i in range(len(list_of_nd_arrays)):\n",
    "        list_of_nd_arrays[i]=list_of_nd_arrays[i].reshape((list_of_nd_arrays[i].shape[0],1))\n",
    "    return nd.concat(*list_of_nd_arrays)\n",
    "\n",
    "\n",
    "def translation_numerical(data,character_dict):\n",
    "    print \"turning characters into numerical representation\"\n",
    "    return_list=[]\n",
    "    for line in data:\n",
    "        return_list.append([character_dict[char] for char in line])\n",
    "    return return_list\n",
    "\n",
    "def numerical_to_nd(one_data,translation_dict):\n",
    "    one_hot = one_hots(one_data, len(translation_dict))\n",
    "    temp = one_hot.reshape((1,1,one_hot.shape[0],one_hot.shape[1]))\n",
    "    temp = nd.swapaxes(temp,0,1)\n",
    "    temp = nd.swapaxes(temp,1,2)\n",
    "    return temp\n",
    "\n",
    "def clean_data(train_data, test_data, threshold_min, threshold_max):\n",
    "    print \"cleaning data\"\n",
    "    train_data_list = []\n",
    "    test_data_list = []\n",
    "    for train_line, test_line in zip(train_data,test_data):\n",
    "            train_line = train_line.lower()\n",
    "            test_line = test_line.lower()  \n",
    "            return_train_line = \"\"\n",
    "            return_test_line = \"\"\n",
    "            \n",
    "            for i in range(len(train_line)):\n",
    "                c = train_line[i]\n",
    "                if((ord(c)==32)or(ord(c)>=97 and ord(c)<=122)):\n",
    "                    return_train_line = return_train_line + c\n",
    "                    \n",
    "            for i in range(len(test_line)):\n",
    "                c = test_line[i]\n",
    "                if((ord(c)==32)or(ord(c)>=97 and ord(c)<=122)):\n",
    "                    return_test_line = return_test_line + c\n",
    "            \n",
    "            if(len(return_train_line)>=threshold_min and len(return_train_line)<=threshold_max):\n",
    "                train_data_list.append(return_train_line)\n",
    "                test_data_list.append(return_test_line)\n",
    "    return train_data_list,test_data_list\n",
    "\n",
    "def pad_zeros(data_numerical):\n",
    "    print \"padding zeros\"\n",
    "    #first, find the maximum length of data.\n",
    "    max_len = 0\n",
    "    for line in data_numerical:\n",
    "        if(len(line)>max_len):\n",
    "            max_len = len(line)\n",
    "            \n",
    "    #iterate through each line and pad with zeros until length equals max_len\n",
    "    for i in range(len(data_numerical)):\n",
    "        data_numerical[i] = data_numerical[i] + [0]*(max_len - len(data_numerical[i]))\n",
    "    \n",
    "    return data_numerical           \n",
    "\n",
    "\n",
    "def rnn_helper(num_hidden, num_inputs, num_outputs): \n",
    "    Wxh = nd.random_normal(shape=(num_inputs,num_hidden), ctx=ctx) * .01\n",
    "    Whh = nd.random_normal(shape=(num_hidden,num_hidden), ctx=ctx) * .01\n",
    "    bh = nd.random_normal(shape=num_hidden, ctx=ctx) * .01\n",
    "    Why = nd.random_normal(shape=(num_hidden,num_outputs), ctx=ctx) * .01\n",
    "    by = nd.random_normal(shape=num_outputs, ctx=ctx) * .01\n",
    "    params = [Wxh, Whh, bh, Why, by]\n",
    "\n",
    "    for param in params:\n",
    "        param.attach_grad()\n",
    "    return params\n",
    " \n",
    "def softmax(y_linear):\n",
    "    exp = nd.exp(y_linear-nd.max(y_linear))\n",
    "    partition = nd.nansum(exp, axis=0, exclude=True)\n",
    "    return exp / partition\n",
    "\n",
    "def encoder(steps, input_data, num_hidden, vocab_size, state, params):\n",
    "    Wxh, Whh, bh, Why, by = params\n",
    "    outputs = []\n",
    "    h = state\n",
    "    for i in range(input_data.shape[0]):\n",
    "        input_temp = nd.dot(input_data[i], Wxh)\n",
    "        hidden_temp = nd.dot(h, Whh)\n",
    "        h_linear = input_temp + hidden_temp + bh\n",
    "        h = nd.tanh(h_linear)\n",
    "        yhat_linear = nd.dot(h, Why) + by\n",
    "        outputs.append(nd.expand_dims(yhat_linear[0],axis=1))\n",
    "    return (outputs, h)\n",
    "\n",
    "\n",
    "def attention_helper(num_attention, num_hidden_encoder, num_hidden_decoder):\n",
    "    W = nd.random_normal(shape=(num_attention,num_hidden_decoder), ctx=ctx) * .01\n",
    "    V = nd.random_normal(shape=(num_attention,num_hidden_encoder), ctx=ctx) * .01\n",
    "    w =  nd.random_normal(shape=(1,num_attention), ctx=ctx) * .01\n",
    "    b = nd.random_normal(shape=(num_attention,1), ctx=ctx) * .01\n",
    "    params = [W,V,w,b]\n",
    "    for param in params:\n",
    "        param.attach_grad()\n",
    "    return params\n",
    "\n",
    "def attention(decoder_hidden, encoder_output, att_params):\n",
    "    W, V, w, b = att_params\n",
    "    decoder_temp = nd.dot(W,decoder_hidden)\n",
    "    encoder_temp = nd.dot(V,encoder_output)\n",
    "    net_temp = nd.reshape(decoder_temp,(decoder_temp.shape[0],1))+encoder_temp+b\n",
    "    return nd.dot(w,nd.tanh(net_temp))\n",
    "    #return nd.dot(softmax(nd.dot(decoder_hidden_t, encoder_output)) , encoder_output.T)\n",
    "\n",
    "\n",
    "def decoder(steps, encoder_outputs, state, num_hidden, vocab_size, params, att_params):\n",
    "    Wxh, Whh, bh, Why, by = params\n",
    "    outputs = []\n",
    "    h = state\n",
    "    # only look at steps long. (consider this 'dynamic')\n",
    "    for i in range(steps):\n",
    "        #h=nd.reshape(h,(1,h.size))\n",
    "        attention_temp = attention(h, encoder_outputs, att_params)\n",
    "        input_recursive_temp = nd.dot(nd.sum(attention_temp*encoder_outputs,axis=1), Wxh)\n",
    "        hidden_recursive_temp = nd.dot(h, Whh)\n",
    "        h = nd.tanh(input_recursive_temp + hidden_recursive_temp + bh)\n",
    "        net_temp = nd.dot(h, Why) + by\n",
    "        yhat = nd.softmax(net_temp)\n",
    "        outputs.append(yhat)\n",
    "    return (outputs, h)   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning data\n",
      "building dictionary\n",
      "building dictionary\n",
      "turning characters into numerical representation\n",
      "turning characters into numerical representation\n",
      "padding zeros\n",
      "padding zeros\n"
     ]
    }
   ],
   "source": [
    "# open the datasets\n",
    "with open(\"../../data/train.en\",\"rb\") as f:\n",
    "    raw_train_data = f.read().splitlines()\n",
    "with open(\"../../data/train.fr\",\"rb\") as f:\n",
    "    raw_train_labels = f.read().splitlines()\n",
    "\n",
    "#clean data\n",
    "train_data, train_labels = clean_data(raw_train_data, raw_train_labels, 100,150)\n",
    "\n",
    "# create dictionary and a character list \n",
    "translation_dict = {}\n",
    "_, num_items = get_char_dict_builder(train_data,translation_dict)\n",
    "_, num_items = get_char_dict_builder(train_labels, translation_dict)\n",
    "character_list = list(translation_dict.keys())\n",
    "\n",
    "# from characters to numerical representations\n",
    "english_numerical=translation_numerical(train_data,translation_dict)\n",
    "french_numerical=translation_numerical(train_labels,translation_dict)\n",
    "\n",
    "# pad zeros\n",
    "data = pad_zeros(english_numerical)\n",
    "labels = pad_zeros(french_numerical)\n",
    "#data = english_numerical\n",
    "#labels = french_numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ctx = mx.cpu()\n",
    "num_hidden = 256\n",
    "learning_rate = 0.001\n",
    "vocab_size = len(translation_dict)\n",
    "encoder_input_size = vocab_size\n",
    "\n",
    "encoder_params = rnn_helper(num_hidden, num_inputs=27, num_outputs=256)\n",
    "encoder_params_1 = rnn_helper(num_hidden, num_inputs=256, num_outputs=256)\n",
    "decoder_params = rnn_helper(num_hidden, num_inputs=256, num_outputs=27) #num_inputs -> vocab_size\n",
    "att_params = attention_helper(num_hidden, num_hidden_encoder=256, num_hidden_decoder=256)\n",
    "\n",
    "params = decoder_params + encoder_params + att_params +encoder_params_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[ -1.47204764e-05   1.97558711e-05  -6.69322571e-06 ...,   5.03512729e-06\n",
      "   -9.69230859e-06   1.03095999e-05]\n",
      " [ -8.62221168e-06   1.15715884e-05  -3.92041557e-06 ...,   2.94922006e-06\n",
      "   -5.67706775e-06   6.03863236e-06]\n",
      " [  2.83530899e-05  -3.80517558e-05   1.28918155e-05 ...,  -9.69815028e-06\n",
      "    1.86683501e-05  -1.98573052e-05]\n",
      " ..., \n",
      " [  3.92454749e-05  -5.26700824e-05   1.78444625e-05 ...,  -1.34238780e-05\n",
      "    2.58401578e-05  -2.74858830e-05]\n",
      " [  4.38650295e-06  -5.88698686e-06   1.99448846e-06 ...,  -1.50039989e-06\n",
      "    2.88817819e-06  -3.07211985e-06]\n",
      " [  1.42943700e-05  -1.91840063e-05   6.49948470e-06 ...,  -4.88937621e-06\n",
      "    9.41175404e-06  -1.00111738e-05]]\n",
      "<NDArray 256x256 @cpu(0)>\n",
      "\n",
      "[[ -1.22609286e-04   1.70499217e-04  -5.26150288e-05 ...,   4.40362746e-05\n",
      "   -8.09964404e-05   8.31332145e-05]\n",
      " [  1.42194651e-04  -1.97867164e-04   6.08857845e-05 ...,  -5.08753546e-05\n",
      "    9.40052123e-05  -9.63207058e-05]\n",
      " [  2.29947254e-05  -3.14759745e-05   1.07867827e-05 ...,  -8.13228235e-06\n",
      "    1.49808729e-05  -1.52495459e-05]\n",
      " ..., \n",
      " [ -4.82119103e-05   6.31378716e-05  -2.37597815e-05 ...,   1.66814243e-05\n",
      "   -3.12529846e-05   3.38612444e-05]\n",
      " [ -7.71697087e-05   1.09293469e-04  -3.13606870e-05 ...,   2.80032837e-05\n",
      "   -5.13486593e-05   5.18791821e-05]\n",
      " [  6.63567262e-05  -9.02862084e-05   2.93204521e-05 ...,  -2.29795478e-05\n",
      "    4.38271054e-05  -4.60522278e-05]]\n",
      "<NDArray 256x256 @cpu(0)>\n",
      "\n",
      "[ 0.00689457 -0.0092228   0.00316217  0.00522647  0.00757153  0.0065885\n",
      "  0.00722865 -0.00728766 -0.00095396  0.00789972  0.00912097 -0.00610406\n",
      " -0.00247159  0.00846266  0.00582339 -0.00258265 -0.00588218  0.00472422\n",
      "  0.00935156  0.00742462  0.00163495  0.01182534  0.00687982  0.00401229\n",
      " -0.00145586 -0.0008098   0.00435133 -0.00408574 -0.00624642 -0.008071\n",
      " -0.00131539  0.00162644  0.00692904 -0.00694837  0.00546064  0.00734708\n",
      "  0.00131068  0.00833272 -0.00646371 -0.00577013 -0.00099048  0.00729969\n",
      "  0.00462255 -0.0076462  -0.00327111 -0.00601019  0.00432721 -0.00388936\n",
      " -0.00575078  0.00657291  0.00271148 -0.01129548  0.00749625  0.00437475\n",
      " -0.00620292  0.00131281 -0.0036035   0.00621788  0.00257176 -0.00616129\n",
      " -0.00100163 -0.0072168   0.00621723  0.00075086  0.00690823 -0.00442697\n",
      " -0.00349633  0.00078541  0.00659555  0.00664358  0.00833566 -0.00018539\n",
      "  0.00094524  0.0100034  -0.00791592  0.00435041  0.00819444 -0.006644\n",
      "  0.00204841  0.00372523 -0.00727362  0.00281728 -0.00445107 -0.00552454\n",
      " -0.00459975  0.004728    0.0060415  -0.00304018  0.00065287  0.00920973\n",
      "  0.00721005  0.00557482  0.00304938  0.00803806  0.00150976 -0.00681602\n",
      "  0.00152534  0.00987558 -0.0069696  -0.00618465  0.00154161 -0.00798076\n",
      " -0.0085531  -0.00429966  0.00715654  0.00448099 -0.00375962 -0.00856589\n",
      " -0.00172641  0.00593391 -0.00633845 -0.00372596 -0.00253549 -0.00321834\n",
      "  0.00733413  0.00224332  0.00060166 -0.00386836 -0.00575114  0.00414773\n",
      " -0.00642548  0.00518563  0.00388032 -0.00668824 -0.00587465  0.00397788\n",
      "  0.00520018  0.0100522   0.00131041 -0.00792308  0.00532984 -0.00511159\n",
      " -0.0062248   0.00596522  0.00502428  0.00406055  0.00345538 -0.004402\n",
      "  0.00866989 -0.00451908 -0.00767302  0.00409306  0.00614893  0.01013656\n",
      " -0.0067157   0.0063706  -0.00629184 -0.00303593 -0.00504503  0.00672656\n",
      " -0.00088701 -0.00515749  0.0103393  -0.00713608  0.00885656  0.00165015\n",
      " -0.00679084  0.00495443 -0.005732    0.00636888  0.00421536  0.00867758\n",
      " -0.00585392  0.00530774 -0.00733358  0.00418716 -0.00911583  0.00181931\n",
      "  0.00937332 -0.00792552  0.00746656 -0.00222094  0.00565503 -0.00271107\n",
      " -0.00538002  0.00374009 -0.00366605  0.00336729  0.00718985  0.00287073\n",
      " -0.00705151 -0.00930799  0.00253311  0.00290973  0.00790234 -0.00488505\n",
      "  0.00804635 -0.00723846  0.00052069 -0.00928848  0.0048666  -0.00254293\n",
      " -0.00718376  0.00490032 -0.00700855 -0.00687949  0.00612028 -0.00212414\n",
      " -0.00465483  0.00413113  0.0072859  -0.00174234 -0.00434543  0.00169589\n",
      " -0.00295329 -0.00616907 -0.00015779  0.00672747  0.00159358 -0.00366565\n",
      "  0.00522519  0.00289143  0.00383355 -0.00114556 -0.00318353 -0.00318448\n",
      " -0.00481726 -0.00468426  0.00756356  0.00273047  0.00618611  0.00203373\n",
      "  0.00447882 -0.0028943   0.00443363  0.00757523 -0.00341229 -0.00530369\n",
      " -0.00010604 -0.00539616 -0.00747275  0.00634216  0.00486593  0.0040708\n",
      "  0.00292402  0.00028227  0.00264077 -0.00186249  0.01120631 -0.00427317\n",
      " -0.00723174 -0.00623762  0.00754122  0.00309601  0.00662947  0.00638639\n",
      " -0.00561532 -0.00717652  0.00050858 -0.00449017  0.00560335  0.00735392\n",
      " -0.00644069 -0.00235126  0.00453448 -0.00483345]\n",
      "<NDArray 256 @cpu(0)>\n",
      "\n",
      "[[  2.63332319e-03   7.08807842e-04   1.74807006e-04 ...,  -5.33142651e-04\n",
      "   -6.66567532e-04  -5.20557340e-04]\n",
      " [ -3.05691175e-03  -8.19714274e-04  -2.01409493e-04 ...,   6.17427111e-04\n",
      "    7.72849715e-04   6.03769091e-04]\n",
      " [ -5.19340741e-04  -1.42511082e-04  -3.72808572e-05 ...,   1.02355712e-04\n",
      "    1.28399392e-04   9.96840972e-05]\n",
      " ..., \n",
      " [  1.02454610e-03   2.83858390e-04   7.30897009e-05 ...,  -2.07913457e-04\n",
      "   -2.58798100e-04  -2.01250703e-04]\n",
      " [  1.65225379e-03   4.39817086e-04   1.06140236e-04 ...,  -3.35339981e-04\n",
      "   -4.19749151e-04  -3.28450260e-04]\n",
      " [ -1.39455765e-03  -3.69636138e-04  -8.88776776e-05 ...,   2.82110181e-04\n",
      "    3.53632960e-04   2.76804814e-04]]\n",
      "<NDArray 256x27 @cpu(0)>\n",
      "\n",
      "[-0.14408463 -0.03839922 -0.00930633  0.03740247 -0.06919254  0.0215951\n",
      "  0.02799046  0.02875352 -0.01551475  0.02162164  0.02866716 -0.03889415\n",
      " -0.0305844  -0.00827909  0.00695943 -0.03135575 -0.02382767 -0.01636749\n",
      "  0.00021173  0.03609613  0.02842503  0.03638994  0.03647517  0.02090635\n",
      "  0.02918497  0.03654303  0.02858389]\n",
      "<NDArray 27 @cpu(0)>\n",
      "\n",
      "[[  2.26308799e-07   3.55090606e-07   1.42198382e-06 ...,   9.69481221e-07\n",
      "   -4.12605345e-08   1.67247407e-07]\n",
      " [ -1.80205859e-07   2.92683808e-07   6.50736752e-07 ...,   6.13935754e-07\n",
      "    2.03088035e-07  -9.42419049e-08]\n",
      " [  1.21932914e-07   8.95188066e-08   1.37133526e-07 ...,   1.66036173e-07\n",
      "    9.37813294e-09   9.18648624e-08]\n",
      " ..., \n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]]\n",
      "<NDArray 27x256 @cpu(0)>\n",
      "\n",
      "[[ -6.88908930e-09   3.32380146e-09   1.83719546e-08 ...,   4.21787449e-09\n",
      "    6.25007601e-09  -1.80865847e-08]\n",
      " [  1.56435220e-08  -4.16117736e-08  -6.51526122e-08 ...,  -6.81365862e-08\n",
      "    9.90454119e-09  -2.86292448e-08]\n",
      " [  1.91432079e-08  -3.11651256e-08  -5.57404896e-08 ...,  -5.34817772e-08\n",
      "    1.97640682e-09  -6.76138256e-09]\n",
      " ..., \n",
      " [  3.34074066e-08  -8.16258066e-08  -1.15672393e-07 ...,  -1.28015955e-07\n",
      "    3.61629260e-09  -5.14683656e-08]\n",
      " [ -1.43912073e-08   2.83301116e-08   5.15494989e-08 ...,   5.31287796e-08\n",
      "   -6.53446008e-09   2.54445442e-08]\n",
      " [  2.28608918e-08  -6.27446113e-08  -1.01785055e-07 ...,  -9.30283903e-08\n",
      "    1.07842633e-08  -3.35943966e-08]]\n",
      "<NDArray 256x256 @cpu(0)>\n",
      "\n",
      "[ -1.40796874e-06   4.19603248e-06   6.38616439e-06   1.86479588e-06\n",
      "   5.96161590e-06  -1.18256185e-06  -5.04473110e-06   1.94201289e-06\n",
      "   1.12523003e-06   1.36101590e-07  -8.44142903e-07  -5.99299392e-06\n",
      "   4.01041598e-06   2.62006483e-06  -6.71753867e-07   1.71711531e-06\n",
      "   6.62515458e-06   1.37284326e-06  -6.27900221e-09   2.38005509e-06\n",
      "  -2.33311198e-07  -3.41101577e-06   2.23611687e-06   2.07845528e-06\n",
      "   4.47418279e-06  -3.83315910e-06  -1.45102638e-06   2.34479330e-06\n",
      "  -7.25897098e-06  -3.08909239e-06  -5.67179040e-06   7.35683716e-06\n",
      "  -9.62495932e-08  -3.78104596e-06   5.13205305e-06   1.88355699e-07\n",
      "  -2.12136547e-06   2.86278294e-07   2.02314868e-06  -1.89787897e-07\n",
      "   1.27802014e-05   4.89738159e-06  -6.14944520e-06  -1.38139558e-06\n",
      "   8.58171552e-06  -3.12539305e-06   3.62686569e-06   1.88039928e-06\n",
      "  -4.30839236e-06   2.89598847e-06   7.00945839e-06  -5.64479296e-06\n",
      "   2.98221539e-06  -3.81990230e-06  -5.35369873e-06  -4.50721473e-06\n",
      "   5.95829704e-07   8.34857929e-06  -4.58625027e-06   3.16835553e-06\n",
      "   1.87080013e-06  -4.15372187e-06  -1.52172595e-06   1.41148860e-06\n",
      "   7.09759888e-07   4.84786960e-06   2.17295428e-06   7.72964449e-06\n",
      "  -6.01471538e-06   2.53551455e-08  -1.74470392e-06  -2.34965705e-06\n",
      "  -4.64546247e-06   7.18605042e-06   3.84466921e-06  -3.80103870e-06\n",
      "  -6.35359675e-06   1.10744134e-06   4.31709779e-08  -7.50299762e-07\n",
      "  -5.67188010e-07   9.20741797e-07  -6.63703076e-07   6.73411796e-06\n",
      "   7.99799000e-06  -5.73614579e-06   3.05507547e-06  -4.64830691e-06\n",
      "  -3.93398864e-07  -9.20428738e-06   5.62568857e-06  -9.03170894e-06\n",
      "   2.32944831e-06   1.27809869e-07   7.41659051e-07   1.54710210e-06\n",
      "   1.19535059e-07   3.40972133e-06  -1.65930274e-07   4.57770511e-07\n",
      "  -3.01441355e-06  -4.16537159e-06  -3.79007247e-06  -4.07218022e-06\n",
      "   3.57352405e-06  -4.59846945e-07  -4.06539925e-07  -7.11912571e-06\n",
      "   1.24007693e-06   2.10045687e-06   1.03726541e-06  -1.47555241e-07\n",
      "   6.25512087e-07   6.36323603e-06  -5.01554450e-06   3.38957943e-06\n",
      "  -9.15540750e-06   2.27695955e-06   6.18922513e-06  -9.03084401e-06\n",
      "   3.13781970e-06  -2.88968135e-06   9.18777403e-07  -4.67841846e-06\n",
      "  -1.11004442e-06  -5.64638549e-06  -1.01070282e-06  -1.07469232e-05\n",
      "  -2.28189924e-06   4.66237509e-07  -9.97804818e-07   8.53688107e-06\n",
      "   2.72501688e-06  -3.10315386e-07  -2.83247232e-06   3.10915607e-06\n",
      "   7.90586284e-07   2.46028617e-06  -8.27184249e-06  -5.46833803e-07\n",
      "   4.00296040e-06   6.16235184e-06  -1.11058353e-06  -6.14398095e-06\n",
      "   1.83902557e-06  -1.46591083e-06   5.06864444e-06  -2.14322131e-06\n",
      "  -5.40256042e-06  -9.21797437e-07   3.35977234e-06  -2.68688268e-06\n",
      "  -5.46865294e-06   3.97039321e-06   2.37387735e-06  -1.98684984e-06\n",
      "   2.87859802e-06   1.80688596e-06  -4.45857404e-06  -3.03950492e-06\n",
      "  -9.52868277e-07  -1.69918974e-06  -2.38055009e-06   5.31595106e-06\n",
      "  -5.97287055e-08   6.31008515e-06   3.84785744e-06  -1.39966005e-06\n",
      "  -7.08025141e-07   4.43064209e-06   2.27228361e-06   2.00865725e-06\n",
      "  -5.51392395e-06   2.80993004e-06   4.17904573e-07   3.84563782e-06\n",
      "   5.11767757e-06   5.68478163e-06   8.26814585e-07   2.53623369e-07\n",
      "   1.17497706e-07  -4.15620946e-07   1.29081104e-06  -4.84573457e-06\n",
      "   1.59696106e-06   3.08396602e-06   1.76613651e-06  -9.34428726e-07\n",
      "  -3.10361293e-06  -4.29545298e-06   2.79197616e-06   1.93665414e-06\n",
      "   9.12818905e-07  -7.67695929e-06  -5.84491863e-06  -1.64453979e-07\n",
      "   5.99683744e-06   2.44861189e-06   6.41779525e-06  -8.17610328e-07\n",
      "   4.31946137e-06  -2.63185666e-06   5.19987498e-06  -3.19507330e-06\n",
      "  -4.33355581e-06  -5.88744479e-06   1.46925606e-06  -2.60706656e-06\n",
      "  -1.66190136e-06   2.30626142e-06   1.80636380e-06   5.11239386e-06\n",
      "   5.39602524e-07   2.37679365e-06  -1.56658984e-06   1.43471880e-06\n",
      "   7.10772156e-07  -9.17448006e-07   9.90861935e-08  -2.95641621e-06\n",
      "  -1.80771565e-06   4.52824133e-06  -1.14694751e-06   2.35846733e-06\n",
      "   3.55036332e-06  -2.53799999e-06   3.63378649e-06   3.33864000e-06\n",
      "   1.61197408e-06   2.70948385e-06  -6.23001915e-06  -3.16648720e-06\n",
      "   8.73611680e-06   6.39888822e-06   2.98572240e-06   3.68520614e-06\n",
      "  -1.14781031e-07  -3.90623336e-06   1.89059870e-06  -4.10843722e-06\n",
      "  -4.74694502e-07   3.11327267e-06  -9.63170896e-06   4.62438356e-06\n",
      "   9.47222816e-07  -1.82455642e-06   4.65219642e-07   2.78330481e-06\n",
      "   1.03312968e-05  -4.94189453e-06  -1.81184419e-06  -1.98313796e-06\n",
      "   9.95413575e-06   6.77915978e-06  -6.80023106e-07   2.81263806e-06]\n",
      "<NDArray 256 @cpu(0)>\n",
      "\n",
      "[[  6.04599393e-08   7.97563189e-08   3.33179777e-08 ...,   7.24977951e-07\n",
      "    5.73211196e-07   1.08102824e-07]\n",
      " [ -1.70846960e-07  -1.41349290e-07  -1.47771019e-07 ...,   3.75223976e-07\n",
      "    3.21208120e-07  -1.07259450e-06]\n",
      " [ -1.85991482e-07  -1.96397167e-07  -1.63073977e-07 ...,   7.89779691e-08\n",
      "   -5.82994232e-07  -6.95174322e-07]\n",
      " ..., \n",
      " [ -2.96843780e-07  -3.01662624e-07  -2.93218278e-07 ...,   1.32169077e-06\n",
      "    7.58526198e-07  -1.25609267e-06]\n",
      " [  1.07780757e-07   1.21703749e-07   1.00914889e-07 ...,  -9.51145353e-07\n",
      "   -1.10672863e-06   9.85920678e-07]\n",
      " [ -2.02910869e-07  -2.41426648e-07  -2.16509136e-07 ...,   7.29337842e-07\n",
      "    8.12586194e-08  -2.32428329e-06]]\n",
      "<NDArray 256x256 @cpu(0)>\n",
      "\n",
      "[  1.69269806e-05   1.47703195e-05   1.57703544e-05   1.48766221e-05\n",
      "   1.49885173e-05   1.71282463e-05   1.35215887e-05   1.82129188e-05\n",
      "   1.34254105e-05   1.51778468e-05   1.61662592e-05   1.52200973e-05\n",
      "   1.71864012e-05   1.34409802e-05   1.53774199e-05   1.65225101e-05\n",
      "   1.44393234e-05   1.66406753e-05   1.48709842e-05   1.65077872e-05\n",
      "   1.40811781e-05   1.62976394e-05   1.52303237e-05   1.46500952e-05\n",
      "   1.79042490e-05   1.34486509e-05   1.58947296e-05   1.50852729e-05\n",
      "   1.57504383e-05   1.67996950e-05   1.41828759e-05   1.55909074e-05\n",
      "   1.49792922e-05   1.50112728e-05   1.73297740e-05   1.37387169e-05\n",
      "   1.79937579e-05   1.37456746e-05   1.45000249e-05   1.63644600e-05\n",
      "   1.54973186e-05   1.66058326e-05   1.43347343e-05   1.53067795e-05\n",
      "   1.64580106e-05   1.47763676e-05   1.61535318e-05   1.41758055e-05\n",
      "   1.72602158e-05   1.42200333e-05   1.56140468e-05   1.54723075e-05\n",
      "   1.50462292e-05   1.77235597e-05   1.29697264e-05   1.61211119e-05\n",
      "   1.49524994e-05   1.53512010e-05   1.72615273e-05   1.41114842e-05\n",
      "   1.55775360e-05   1.56821025e-05   1.47444071e-05   1.66166010e-05\n",
      "   1.45591812e-05   1.72246073e-05   1.38758487e-05   1.49506914e-05\n",
      "   1.63374661e-05   1.50151636e-05   1.64745688e-05   1.47211931e-05\n",
      "   1.57755712e-05   1.53287037e-05   1.51454851e-05   1.65240326e-05\n",
      "   1.38282148e-05   1.76332469e-05   1.37332590e-05   1.55270791e-05\n",
      "   1.61757871e-05   1.52038820e-05   1.71267657e-05   1.28289521e-05\n",
      "   1.61988773e-05   1.54203444e-05   1.53880956e-05   1.72811524e-05\n",
      "   1.40755110e-05   1.60032068e-05   1.46755865e-05   1.57113882e-05\n",
      "   1.64760768e-05   1.40947304e-05   1.73045992e-05   1.34764132e-05\n",
      "   1.62837150e-05   1.52856574e-05   1.52703778e-05   1.66434620e-05\n",
      "   1.47372029e-05   1.54685658e-05   1.49436346e-05   1.52720058e-05\n",
      "   1.68115093e-05   1.37136403e-05   1.80013885e-05   1.33410795e-05\n",
      "   1.56307360e-05   1.60667369e-05   1.54589143e-05   1.65634592e-05\n",
      "   1.36775479e-05   1.55405687e-05   1.59257543e-05   1.48110266e-05\n",
      "   1.65398797e-05   1.51531449e-05   1.54551963e-05   1.47841929e-05\n",
      "   1.59252941e-05   1.58415114e-05   1.45335498e-05   1.74566776e-05\n",
      "   1.32674004e-05   1.67626313e-05   1.45330132e-05   1.58877665e-05\n",
      "   1.67215658e-05   1.46049442e-05   1.57169688e-05   1.48809813e-05\n",
      "   1.49901261e-05   1.71149113e-05   1.35205837e-05   1.82241656e-05\n",
      "   1.34284646e-05   1.51677305e-05   1.61683274e-05   1.52387638e-05\n",
      "   1.73113312e-05   1.34044922e-05   1.53535566e-05   1.65469046e-05\n",
      "   1.44378710e-05   1.65773617e-05   1.48631234e-05   1.65118618e-05\n",
      "   1.40576612e-05   1.62373981e-05   1.51706317e-05   1.46210077e-05\n",
      "   1.78082737e-05   1.34309157e-05   1.59089486e-05   1.51006197e-05\n",
      "   1.57576651e-05   1.67629933e-05   1.41558494e-05   1.55110647e-05\n",
      "   1.50042642e-05   1.50038541e-05   1.72437067e-05   1.36877734e-05\n",
      "   1.79312956e-05   1.37192201e-05   1.44887817e-05   1.63898694e-05\n",
      "   1.55443540e-05   1.66824939e-05   1.43185016e-05   1.53174533e-05\n",
      "   1.65161309e-05   1.48235886e-05   1.61942025e-05   1.41828687e-05\n",
      "   1.73031840e-05   1.42299814e-05   1.56692149e-05   1.54994032e-05\n",
      "   1.50459955e-05   1.77043712e-05   1.29441396e-05   1.61217104e-05\n",
      "   1.50078986e-05   1.54166646e-05   1.73844273e-05   1.41361461e-05\n",
      "   1.55528214e-05   1.56922233e-05   1.47627961e-05   1.66381251e-05\n",
      "   1.45619233e-05   1.72340206e-05   1.38663627e-05   1.49911702e-05\n",
      "   1.63994755e-05   1.50159995e-05   1.65729853e-05   1.47790070e-05\n",
      "   1.58020539e-05   1.53321398e-05   1.51073100e-05   1.64722205e-05\n",
      "   1.38145933e-05   1.77007241e-05   1.37209117e-05   1.55344824e-05\n",
      "   1.61808548e-05   1.51977583e-05   1.70863023e-05   1.28290503e-05\n",
      "   1.61562766e-05   1.53770288e-05   1.53746241e-05   1.72922482e-05\n",
      "   1.40835909e-05   1.60402979e-05   1.46609564e-05   1.57412105e-05\n",
      "   1.65374604e-05   1.40902002e-05   1.73656845e-05   1.35355140e-05\n",
      "   1.63906989e-05   1.52536086e-05   1.51754321e-05   1.67607450e-05\n",
      "   1.47452329e-05   1.54647587e-05   1.49402958e-05   1.52615012e-05\n",
      "   1.68013739e-05   1.37024426e-05   1.79472718e-05   1.33561862e-05\n",
      "   1.57202358e-05   1.60159852e-05   1.53122037e-05   1.65453566e-05\n",
      "   1.37271581e-05   1.55826219e-05   1.59219653e-05   1.48220142e-05\n",
      "   1.66584414e-05   1.50842407e-05   1.52930970e-05   1.48803938e-05\n",
      "   1.68753231e-05   1.54714398e-05   1.34459988e-05   3.09199131e-05\n",
      "   2.36394153e-05  -4.51933411e-05  -3.16668084e-05   1.04564824e-04]\n",
      "<NDArray 256 @cpu(0)>\n",
      "\n",
      "[[  1.48834306e-05  -1.72088166e-05  -2.84291423e-06 ...,   6.21759727e-06\n",
      "    9.17052785e-06  -8.12922553e-06]\n",
      " [ -2.08796700e-06   2.41419184e-06   3.98826785e-07 ...,  -8.72255214e-07\n",
      "   -1.28651538e-06   1.14043348e-06]\n",
      " [  9.75026296e-07  -1.12736461e-06  -1.86241707e-07 ...,   4.07319931e-07\n",
      "    6.00769567e-07  -5.32552463e-07]\n",
      " ..., \n",
      " [  4.52594747e-07  -5.23308131e-07  -8.64509673e-08 ...,   1.89072864e-07\n",
      "    2.78869379e-07  -2.47204099e-07]\n",
      " [ -1.78182272e-05   2.06021432e-05   3.40348902e-06 ...,  -7.44360887e-06\n",
      "   -1.09788361e-05   9.73219085e-06]\n",
      " [  4.30219825e-06  -4.97437259e-06  -8.21772346e-07 ...,   1.79724452e-06\n",
      "    2.65083554e-06  -2.34982122e-06]]\n",
      "<NDArray 256x256 @cpu(0)>\n",
      "\n",
      "[[  3.28077067e-06   1.89056959e-06  -6.35639526e-06 ...,  -8.79383970e-06\n",
      "   -9.80694153e-07  -3.18322327e-06]\n",
      " [ -4.60253204e-07  -2.65224514e-07   8.91726643e-07 ...,   1.23367124e-06\n",
      "    1.37579732e-07   4.46568492e-07]\n",
      " [  2.14926018e-07   1.23852772e-07  -4.16412746e-07 ...,  -5.76091793e-07\n",
      "   -6.42461018e-08  -2.08535667e-07]\n",
      " ..., \n",
      " [  9.97660266e-08   5.74909613e-08  -1.93293573e-07 ...,  -2.67414634e-07\n",
      "   -2.98222318e-08  -9.67996314e-08]\n",
      " [ -3.92768970e-06  -2.26336147e-06   7.60978082e-06 ...,   1.05278541e-05\n",
      "    1.17407228e-06   3.81090763e-06]\n",
      " [  9.48332911e-07   5.46484330e-07  -1.83736597e-06 ...,  -2.54192923e-06\n",
      "   -2.83477419e-07  -9.20135903e-07]]\n",
      "<NDArray 256x256 @cpu(0)>\n",
      "\n",
      "[[ -6.49077818e-04   2.95423175e-04  -3.72812734e-04   4.85751953e-04\n",
      "   -3.15891491e-04  -3.94900242e-04   3.21802567e-04   1.66185258e-04\n",
      "   -6.77641539e-04   6.26393012e-05   2.59231572e-04   8.04248790e-04\n",
      "    2.10604136e-04  -4.83863143e-04   7.52837397e-04   2.13478663e-04\n",
      "    1.63309174e-04  -1.47415194e-04  -7.81549665e-04  -5.61167370e-04\n",
      "   -3.99493991e-04  -2.27297583e-04   2.52414902e-04  -4.95185086e-05\n",
      "   -3.16463178e-04  -6.05531677e-04   2.12677434e-04   4.00255522e-04\n",
      "    1.76298723e-04  -8.70572170e-04   1.91169136e-04   4.15574759e-04\n",
      "    1.19794498e-03  -1.02637243e-03  -4.76771995e-04   4.24924307e-04\n",
      "   -7.59995950e-04  -3.82559811e-04  -5.00372611e-04   1.95972068e-04\n",
      "   -1.32425048e-03   4.55417874e-04   3.80686215e-05   6.16512785e-04\n",
      "    8.21409805e-04   2.36829655e-04   4.86513134e-04   1.49617286e-03\n",
      "   -9.87474690e-04   8.59366322e-04  -4.49405605e-04   4.99500544e-04\n",
      "   -1.40961609e-03  -9.49297464e-05   6.59906800e-05  -6.64368854e-04\n",
      "   -2.96990765e-04  -2.45556585e-04   3.93454429e-05  -4.24754253e-04\n",
      "    2.79435539e-04   1.27580963e-04   3.12256627e-04   2.06323763e-04\n",
      "    4.82614487e-05  -7.49657120e-05  -1.24225844e-04   2.20901071e-04\n",
      "    4.29045409e-04   4.83285461e-04   3.13656434e-04  -4.96262976e-04\n",
      "   -1.00759009e-03   3.19957267e-04   3.09390976e-04  -3.74311203e-04\n",
      "   -2.23078168e-05   8.91019881e-04   3.73683957e-04   9.43189196e-04\n",
      "   -4.79477952e-04  -1.16962525e-04  -4.64808109e-04   9.58118238e-04\n",
      "    3.69173184e-04  -5.71897719e-04   6.13120443e-04   1.66359794e-04\n",
      "   -3.29163042e-04  -9.90504283e-04   2.66215735e-04  -5.08691417e-04\n",
      "    3.63869214e-04  -2.93083227e-04   1.44176054e-04  -1.09296083e-03\n",
      "   -8.54766986e-04   4.81824914e-04  -1.10157754e-03   1.86399760e-04\n",
      "   -1.03895133e-03  -1.62539596e-04   6.42689411e-04   1.98820489e-04\n",
      "   -2.93765799e-04   5.29211131e-04  -2.39865476e-04   7.17844407e-04\n",
      "   -2.07541208e-03  -8.93431366e-04   5.90534299e-04   3.90395959e-04\n",
      "    1.23957195e-03   6.44879328e-05   7.37420982e-04  -3.15999583e-04\n",
      "   -4.24050173e-04   2.45465228e-04   1.53845060e-03  -5.52319165e-04\n",
      "    5.05455595e-04   8.15667154e-04  -3.24561959e-04   6.11461932e-04\n",
      "    7.74501241e-04  -1.60641081e-04   9.14445031e-04  -1.86156933e-04\n",
      "    8.70456104e-04  -2.11023053e-05   7.39344396e-04  -9.34542797e-04\n",
      "   -8.52292462e-04   4.69239400e-04   1.08206982e-03   3.43180232e-04\n",
      "   -2.14899446e-05   5.54074300e-04  -9.34785523e-04   4.52557229e-04\n",
      "    1.07218081e-03  -7.56689697e-04  -2.34421896e-04  -8.24579038e-04\n",
      "    4.12472989e-04  -4.86457662e-04  -3.95583251e-04  -2.34423846e-04\n",
      "   -1.51214877e-03  -9.77419433e-04   5.91723074e-04   3.19776416e-04\n",
      "   -7.77721114e-04  -9.96143091e-04   8.53511097e-04  -9.82568250e-04\n",
      "    4.24635742e-04   1.47918623e-03  -5.36801293e-04   4.79642549e-05\n",
      "   -1.10222050e-03  -1.32059189e-03  -1.67417558e-04   3.44260130e-04\n",
      "    6.74029987e-04   1.22243038e-03  -6.38746074e-04  -2.47949560e-04\n",
      "    7.04179751e-04   2.74470949e-04  -7.06174935e-04  -4.77022608e-04\n",
      "    8.28225748e-04   1.53386736e-05   5.44405018e-04  -1.77652124e-04\n",
      "    3.18887673e-04   9.56404721e-04   1.70846979e-04  -1.19784556e-03\n",
      "   -6.55559998e-04   1.20129285e-03   6.84080878e-05   3.79445293e-04\n",
      "    1.03167273e-04  -2.61696812e-04  -3.48679576e-04  -3.13644632e-05\n",
      "    1.19288830e-04  -3.82916012e-04   6.96182600e-04  -3.31529242e-04\n",
      "   -5.07084245e-04   4.01829893e-05  -1.80765855e-04  -6.38183519e-06\n",
      "   -8.37545231e-05  -1.09503488e-03   1.69413819e-04  -4.09902015e-04\n",
      "   -3.08517483e-04   2.30175392e-05  -7.33945693e-04  -4.71456442e-04\n",
      "    9.12972086e-04  -1.11021334e-03   1.31473746e-04   4.06203726e-05\n",
      "    2.98080529e-04   6.09115872e-04   8.08863551e-04  -3.61981103e-04\n",
      "    1.73150183e-04   3.88471788e-04   1.56594126e-03  -1.67893362e-04\n",
      "    1.60988100e-04   1.15574185e-04   4.42470133e-04   8.52445373e-04\n",
      "   -7.72554835e-04  -4.53501299e-04   5.72179735e-04  -5.92389733e-06\n",
      "   -6.32369716e-04  -5.04933239e-04  -4.11752902e-04  -4.57996997e-04\n",
      "    1.31453198e-05   3.51240044e-04   3.00902670e-04   1.03862221e-05\n",
      "    5.50908037e-04  -1.35947354e-04   3.18904058e-04   2.57197855e-04\n",
      "    1.70055020e-03   1.29202823e-03   7.73598906e-04  -2.53872509e-04\n",
      "   -1.30233378e-03  -5.70409000e-04   5.97045466e-04   4.78192524e-04\n",
      "   -7.51683663e-04   2.58098531e-04  -2.54124810e-04  -6.94753428e-04\n",
      "   -1.35193899e-04   2.88990850e-04   2.01408286e-04   4.17447940e-04\n",
      "   -2.57835141e-04  -4.82486997e-04   6.35689066e-04   5.76711085e-04]]\n",
      "<NDArray 1x256 @cpu(0)>\n",
      "\n",
      "[[ -8.57193780e-04]\n",
      " [  1.20254073e-04]\n",
      " [ -5.61554698e-05]\n",
      " [  4.90044535e-04]\n",
      " [ -3.09267838e-04]\n",
      " [ -8.78741499e-04]\n",
      " [ -1.00759484e-04]\n",
      " [ -8.15419422e-04]\n",
      " [ -2.36058535e-04]\n",
      " [  5.73832513e-05]\n",
      " [  1.06519938e-03]\n",
      " [ -2.17491484e-04]\n",
      " [ -1.19289711e-04]\n",
      " [ -8.33569735e-04]\n",
      " [  1.28241337e-03]\n",
      " [  5.91454329e-04]\n",
      " [  2.51431629e-04]\n",
      " [  2.87546078e-04]\n",
      " [ -4.66800673e-04]\n",
      " [  8.64141839e-05]\n",
      " [ -1.13374597e-04]\n",
      " [  3.23608052e-04]\n",
      " [  8.16153624e-05]\n",
      " [ -1.23619975e-04]\n",
      " [ -1.28749572e-03]\n",
      " [ -8.57287610e-04]\n",
      " [ -2.31388927e-04]\n",
      " [ -6.30711671e-04]\n",
      " [ -9.56707809e-05]\n",
      " [  1.54679929e-05]\n",
      " [ -8.02200579e-04]\n",
      " [  4.08669614e-04]\n",
      " [ -1.00955709e-04]\n",
      " [  1.89902305e-04]\n",
      " [ -3.83329985e-04]\n",
      " [  4.05913044e-04]\n",
      " [  8.84776062e-04]\n",
      " [ -2.12643718e-05]\n",
      " [ -1.44391452e-04]\n",
      " [  7.74421904e-04]\n",
      " [ -4.14708571e-04]\n",
      " [  8.92628508e-04]\n",
      " [  4.51636995e-04]\n",
      " [  7.00720004e-04]\n",
      " [ -7.92833278e-04]\n",
      " [  3.60448248e-05]\n",
      " [ -5.08366677e-04]\n",
      " [  1.42256694e-03]\n",
      " [  6.35772521e-05]\n",
      " [ -2.77011801e-04]\n",
      " [  9.20192997e-06]\n",
      " [ -3.05195252e-04]\n",
      " [ -1.46032879e-04]\n",
      " [  1.47649800e-04]\n",
      " [ -2.22413437e-04]\n",
      " [ -6.98618824e-05]\n",
      " [  3.29482864e-04]\n",
      " [ -6.33038173e-04]\n",
      " [ -1.99989572e-05]\n",
      " [  3.86687258e-04]\n",
      " [ -6.64008025e-04]\n",
      " [  3.92410060e-04]\n",
      " [ -9.16616118e-05]\n",
      " [ -3.29715200e-04]\n",
      " [ -1.18936913e-03]\n",
      " [ -4.00328980e-04]\n",
      " [ -6.20694482e-04]\n",
      " [ -3.22145876e-04]\n",
      " [ -5.92082215e-04]\n",
      " [  1.47283819e-04]\n",
      " [  1.65127742e-04]\n",
      " [ -2.60200643e-04]\n",
      " [  2.04749624e-04]\n",
      " [ -5.70748176e-04]\n",
      " [ -9.58950724e-04]\n",
      " [  1.76165567e-03]\n",
      " [  9.01354942e-04]\n",
      " [  1.86345904e-04]\n",
      " [ -8.57937557e-04]\n",
      " [  6.69947534e-04]\n",
      " [  8.12452578e-04]\n",
      " [  3.45803885e-04]\n",
      " [ -4.52371532e-05]\n",
      " [  8.70847201e-04]\n",
      " [ -3.48472313e-05]\n",
      " [  1.11997826e-03]\n",
      " [ -5.27636323e-04]\n",
      " [ -4.38741438e-07]\n",
      " [  1.15025119e-04]\n",
      " [ -4.27554332e-04]\n",
      " [ -4.04824881e-04]\n",
      " [ -8.67115450e-04]\n",
      " [ -5.42759895e-04]\n",
      " [ -8.07648117e-04]\n",
      " [  3.44457309e-04]\n",
      " [  6.70799636e-04]\n",
      " [  8.98829720e-04]\n",
      " [  7.30573898e-04]\n",
      " [  5.70066040e-04]\n",
      " [ -2.58012733e-04]\n",
      " [ -8.44553637e-04]\n",
      " [ -4.30123240e-04]\n",
      " [ -8.62827656e-05]\n",
      " [  3.03594006e-05]\n",
      " [ -7.29105202e-04]\n",
      " [  1.11417329e-07]\n",
      " [  4.86094268e-06]\n",
      " [ -7.69099715e-05]\n",
      " [ -2.73549143e-04]\n",
      " [  1.15837192e-03]\n",
      " [  1.33729962e-04]\n",
      " [ -1.39444339e-04]\n",
      " [  5.40136360e-04]\n",
      " [ -3.38504819e-04]\n",
      " [  5.58352738e-04]\n",
      " [ -1.28514846e-04]\n",
      " [ -4.87150624e-04]\n",
      " [  1.26969500e-03]\n",
      " [  4.78121248e-04]\n",
      " [  1.23671067e-04]\n",
      " [  9.40466882e-04]\n",
      " [  6.31272851e-04]\n",
      " [ -4.46368285e-05]\n",
      " [ -3.77095770e-04]\n",
      " [ -1.15737557e-05]\n",
      " [ -1.17749751e-05]\n",
      " [  8.48266820e-04]\n",
      " [ -6.22714695e-04]\n",
      " [ -6.40820828e-04]\n",
      " [  1.27401945e-05]\n",
      " [  6.44830288e-04]\n",
      " [ -8.43682210e-04]\n",
      " [ -2.78366526e-04]\n",
      " [  1.23872975e-04]\n",
      " [ -1.24988775e-03]\n",
      " [  2.45061790e-04]\n",
      " [  8.16353248e-04]\n",
      " [  8.37994230e-05]\n",
      " [ -6.93048874e-04]\n",
      " [ -9.04854605e-05]\n",
      " [ -7.54631532e-04]\n",
      " [ -5.66937146e-04]\n",
      " [ -4.22582496e-04]\n",
      " [ -6.20349136e-04]\n",
      " [  4.29280277e-04]\n",
      " [ -5.47579082e-04]\n",
      " [ -1.20883726e-03]\n",
      " [ -2.04856871e-04]\n",
      " [ -6.19219383e-04]\n",
      " [ -7.27739476e-04]\n",
      " [  9.69772402e-04]\n",
      " [ -1.41848534e-04]\n",
      " [ -1.76929258e-04]\n",
      " [ -1.38664956e-03]\n",
      " [  2.81412271e-04]\n",
      " [ -1.02965382e-03]\n",
      " [  4.47842642e-04]\n",
      " [  9.86532425e-04]\n",
      " [  1.20081240e-04]\n",
      " [ -1.38005431e-04]\n",
      " [  5.08502009e-04]\n",
      " [ -9.23780608e-05]\n",
      " [ -2.89590651e-04]\n",
      " [  1.31164765e-04]\n",
      " [ -9.81467892e-05]\n",
      " [  9.35939956e-04]\n",
      " [  8.08189972e-04]\n",
      " [  3.65509506e-04]\n",
      " [ -1.46289676e-04]\n",
      " [ -6.58666031e-05]\n",
      " [ -8.08540499e-04]\n",
      " [  6.74458279e-04]\n",
      " [  5.39532630e-04]\n",
      " [ -5.31870872e-04]\n",
      " [ -2.17988127e-04]\n",
      " [  4.00300894e-04]\n",
      " [  1.47004452e-04]\n",
      " [  2.46964657e-04]\n",
      " [ -5.37849439e-04]\n",
      " [ -9.12899384e-04]\n",
      " [ -1.61055636e-04]\n",
      " [  1.29473605e-03]\n",
      " [  1.39012304e-03]\n",
      " [ -4.04005783e-04]\n",
      " [ -6.71248708e-05]\n",
      " [  1.57111936e-04]\n",
      " [  5.96813989e-05]\n",
      " [ -9.36399301e-05]\n",
      " [ -6.18080157e-05]\n",
      " [ -7.75265798e-05]\n",
      " [  1.27021607e-03]\n",
      " [ -2.88592826e-04]\n",
      " [  8.07458244e-04]\n",
      " [ -2.95782724e-04]\n",
      " [  4.66950267e-04]\n",
      " [  1.24602416e-03]\n",
      " [  1.90665334e-04]\n",
      " [ -2.44728435e-04]\n",
      " [  8.25937313e-05]\n",
      " [  4.89647791e-04]\n",
      " [  6.88645669e-05]\n",
      " [ -9.23079133e-05]\n",
      " [ -1.12080225e-03]\n",
      " [  5.56149789e-05]\n",
      " [  2.83911475e-04]\n",
      " [  7.80660775e-05]\n",
      " [  1.71531702e-03]\n",
      " [  4.41631157e-04]\n",
      " [ -1.51777160e-04]\n",
      " [  6.77819597e-04]\n",
      " [  4.43364610e-04]\n",
      " [  1.71588594e-03]\n",
      " [ -4.49615531e-04]\n",
      " [ -5.16217369e-05]\n",
      " [ -1.66908794e-05]\n",
      " [  7.45203404e-04]\n",
      " [  9.20618884e-04]\n",
      " [  2.60518806e-04]\n",
      " [ -8.30376113e-04]\n",
      " [  5.57150692e-04]\n",
      " [ -3.23661719e-04]\n",
      " [  8.70687654e-05]\n",
      " [ -5.29969228e-04]\n",
      " [ -6.47362205e-04]\n",
      " [ -2.78561434e-04]\n",
      " [  5.50989353e-04]\n",
      " [ -3.75289994e-04]\n",
      " [ -9.84061262e-06]\n",
      " [  7.77689216e-04]\n",
      " [ -9.70188339e-05]\n",
      " [  8.55409482e-04]\n",
      " [ -6.41935403e-05]\n",
      " [  2.51629663e-05]\n",
      " [  1.18396746e-03]\n",
      " [  2.16885564e-05]\n",
      " [ -8.67733906e-05]\n",
      " [ -6.86070416e-05]\n",
      " [  2.99265201e-04]\n",
      " [  1.51068671e-04]\n",
      " [  3.63544590e-04]\n",
      " [ -8.54501995e-05]\n",
      " [ -8.55891267e-04]\n",
      " [ -6.00340019e-04]\n",
      " [ -3.85783322e-04]\n",
      " [  5.03010815e-04]\n",
      " [ -4.32211935e-04]\n",
      " [ -6.50754373e-04]\n",
      " [  1.63995777e-04]\n",
      " [  6.89730688e-04]\n",
      " [  2.03819596e-04]\n",
      " [ -1.11716385e-04]\n",
      " [ -2.86765862e-04]\n",
      " [ -3.65838700e-04]\n",
      " [ -2.60666729e-05]\n",
      " [  1.02621957e-03]\n",
      " [ -2.47778662e-04]]\n",
      "<NDArray 256x1 @cpu(0)>\n",
      "\n",
      "[[  5.40884344e-07  -8.23037226e-07   2.76582483e-07 ...,  -2.86460420e-08\n",
      "    8.02346108e-07  -2.94800316e-07]\n",
      " [  5.03199828e-07  -7.71328473e-07   2.62546877e-07 ...,  -1.41265843e-08\n",
      "    7.56377062e-07  -2.70020166e-07]\n",
      " [  5.48172352e-07  -8.13239694e-07   2.81404425e-07 ...,  -1.63292526e-08\n",
      "    8.03742466e-07  -2.92097639e-07]\n",
      " ..., \n",
      " [  1.68460204e-07   5.30908096e-07   1.48645640e-07 ...,   5.57623821e-07\n",
      "   -7.02094383e-08   2.87725527e-07]\n",
      " [  3.77688849e-07   2.79864025e-08   2.36855342e-07 ...,   3.85692289e-07\n",
      "    3.04748625e-07   6.83868393e-08]\n",
      " [  2.21212161e-07   5.97022449e-07   2.14770182e-07 ...,   7.18951014e-07\n",
      "   -2.16002150e-08   3.65171275e-07]]\n",
      "<NDArray 256x256 @cpu(0)>\n",
      "\n",
      "[[ -1.16242336e-06   1.04613332e-06  -7.86095200e-07 ...,  -7.49054891e-07\n",
      "   -1.57657291e-06   1.06388747e-07]\n",
      " [  9.76014235e-07  -9.12923326e-07   6.64416348e-07 ...,   6.22682933e-07\n",
      "    1.34674247e-06  -9.24190999e-08]\n",
      " [  8.48093237e-07  -7.71693635e-07   5.65787786e-07 ...,   5.18249294e-07\n",
      "    1.14390730e-06  -9.87911122e-08]\n",
      " ..., \n",
      " [  6.86855515e-07  -6.61005117e-07   4.59659248e-07 ...,   4.09682656e-07\n",
      "    9.48145839e-07  -8.29597795e-08]\n",
      " [ -1.56963313e-06   1.24093458e-06  -1.11862164e-06 ...,  -1.23873610e-06\n",
      "   -2.10948792e-06  -7.43085282e-09]\n",
      " [ -2.96587132e-07   3.18046403e-07  -2.13398735e-07 ...,  -1.96639462e-07\n",
      "   -4.42963994e-07   2.05740527e-08]]\n",
      "<NDArray 256x256 @cpu(0)>\n",
      "\n",
      "[ -1.58211173e-04   1.37523544e-04  -1.11243935e-04  -5.39754546e-05\n",
      "  -2.42201306e-04  -2.29621975e-04  -6.01205174e-05   7.97537068e-05\n",
      "  -3.56415512e-06  -1.12015732e-04   8.05380041e-05  -3.01396940e-04\n",
      "  -3.47727910e-05  -1.40917677e-04   1.79781418e-04   2.02465599e-04\n",
      "   5.94428675e-05  -1.95847810e-04   1.98638489e-04  -1.09505047e-04\n",
      "   1.49172658e-04   3.71981383e-04  -1.18461387e-04   8.89897492e-05\n",
      "  -1.40403659e-04  -2.14750718e-04   1.00971745e-04   1.93523694e-04\n",
      "   2.03089468e-04  -2.74290476e-04  -1.51862827e-04   2.44972587e-04\n",
      "   3.50424707e-05  -3.62354767e-04  -2.00163340e-04   2.13764943e-04\n",
      "  -8.65983238e-05   3.70644921e-05  -2.16972549e-04  -2.03624604e-05\n",
      "   8.39614586e-05   2.35545194e-05   8.45891336e-05   1.16254902e-04\n",
      "  -4.65681251e-06  -5.16943546e-05  -2.60593351e-05   1.41842029e-04\n",
      "   2.45506177e-04   9.73588976e-05   2.17687804e-04  -9.25404820e-05\n",
      "   1.48322084e-04   1.86888617e-04   4.73115651e-05   2.08515208e-04\n",
      "   2.52327009e-04   1.69595543e-04   1.47643281e-04  -1.04371466e-04\n",
      "  -6.89034277e-05   9.88458942e-06  -1.60614087e-04  -5.48803509e-05\n",
      "  -6.38926795e-05  -3.20284089e-05  -5.83624660e-06   2.17342968e-04\n",
      "   8.18859771e-05   1.35153707e-04   2.05995439e-05   2.59233784e-04\n",
      "   1.45192054e-04   2.28700563e-04   6.34897660e-05   2.24229734e-04\n",
      "   1.98756054e-04   1.01850070e-04   1.99843998e-04  -8.60589789e-05\n",
      "  -1.14541079e-04   3.18645529e-04   1.31231063e-04  -1.66588026e-04\n",
      "   1.00471101e-04  -2.08020065e-05   1.21926845e-04   1.40535585e-05\n",
      "   1.53622037e-04  -1.21264377e-04   1.42565113e-04   1.76038850e-06\n",
      "  -1.63918812e-04   1.24070095e-04   6.62156381e-05   1.75038760e-04\n",
      "  -5.37560154e-05   1.41634315e-04   1.68565908e-04  -9.03834298e-05\n",
      "  -2.46660493e-04   1.75753245e-04  -3.17663284e-06  -3.99724959e-05\n",
      "  -9.33453630e-05   4.38766234e-04  -3.71969363e-04  -1.96829147e-04\n",
      "  -4.52178356e-05   3.06867805e-05   2.13022013e-05  -2.02239738e-04\n",
      "   7.26238504e-05  -1.11556314e-04   1.12062735e-04  -1.82854149e-06\n",
      "  -9.28874942e-06   1.67283317e-04   1.08272725e-04  -8.47681367e-05\n",
      "   1.23611913e-04   4.60233605e-05   6.42190644e-05  -4.02268561e-05\n",
      "   1.19719429e-04   8.07428751e-06   4.19076998e-04   1.00166493e-04\n",
      "  -5.83997280e-05  -2.14795655e-04   2.34425228e-04  -5.14423155e-05\n",
      "   1.41803073e-04  -9.57228767e-05   3.06014335e-05   2.19354333e-04\n",
      "   4.95999266e-05   1.59107512e-04  -1.14471892e-04   2.13921114e-04\n",
      "  -9.48586166e-05   8.80496154e-05   1.06349231e-04   2.23869909e-04\n",
      "  -7.10174281e-05  -3.25715519e-04   5.79443213e-06  -2.69349530e-05\n",
      "  -6.36216719e-05  -1.31194625e-04   3.03884415e-04  -3.52491625e-04\n",
      "  -5.39817411e-05   7.76588568e-05  -2.75704020e-04   2.23176947e-04\n",
      "  -1.62843222e-04  -1.31690846e-04  -7.57821108e-05  -1.47547529e-04\n",
      "   2.19603331e-04   1.23157622e-06  -4.34023386e-04   2.24553733e-04\n",
      "  -2.22387869e-04   2.93205871e-04  -1.75494879e-05   2.08387064e-04\n",
      "  -5.10892933e-05  -1.65554375e-04   1.13304035e-04   8.81250380e-05\n",
      "   2.42981594e-04   1.11140071e-04  -2.08244761e-04   1.41725759e-04\n",
      "  -5.22829487e-06   3.83195038e-05  -2.28187870e-04  -5.83814908e-05\n",
      "   7.65730292e-05  -2.25786614e-04   4.49637591e-05  -9.50434332e-05\n",
      "  -2.35067899e-04   1.55396541e-04   1.27471663e-04  -1.50989741e-04\n",
      "  -2.82787914e-05  -1.52542358e-04  -1.03341144e-05  -8.77974162e-05\n",
      "  -1.23264588e-04  -9.86460509e-05  -2.35838612e-04  -1.88984413e-04\n",
      "   1.74314962e-04  -3.36048324e-05   5.40379879e-05  -2.94431084e-04\n",
      "   5.01711220e-05   2.65115377e-04  -1.17964839e-04  -1.36764575e-04\n",
      "   5.42024281e-06  -3.31481897e-05  -2.47217336e-04   2.55764084e-04\n",
      "   1.34862436e-04   1.66212740e-05  -4.18013187e-05  -1.78118935e-04\n",
      "   1.04833443e-05  -1.44631122e-04   7.90994964e-05  -5.19950081e-05\n",
      "   1.40579868e-04  -2.20395868e-05  -3.01783120e-06   1.00616104e-04\n",
      "  -2.94121273e-04  -1.46510662e-04  -2.61847672e-05  -1.43855345e-04\n",
      "   3.95682546e-05   1.64827870e-04   1.26043335e-04  -3.77257165e-05\n",
      "   2.05846925e-04  -1.94740715e-04  -4.68456055e-05  -1.28229600e-04\n",
      "   1.94709966e-04   1.57502785e-04  -3.89707056e-05  -3.94311392e-05\n",
      "   1.37425348e-04  -4.40081612e-06  -1.46814287e-04  -1.91987725e-04\n",
      "   4.91002138e-05   1.41172510e-04  -1.43910904e-04  -7.14855050e-05\n",
      "   2.34010426e-04   1.21754107e-04  -1.22477082e-04  -3.90520254e-05\n",
      "   2.59494263e-04   1.77140246e-04  -8.12552244e-05   2.61101581e-04\n",
      "  -1.32819012e-04  -1.14696566e-04  -2.17089560e-04   5.88339117e-06]\n",
      "<NDArray 256 @cpu(0)>\n",
      "\n",
      "[[ -1.19019560e-05   9.70132714e-06   3.19509058e-06 ...,   7.69715882e-07\n",
      "    2.71745103e-06   6.00638168e-06]\n",
      " [  9.84748931e-06  -8.02398790e-06  -2.64531627e-06 ...,  -6.41512599e-07\n",
      "   -2.25374333e-06  -4.98141071e-06]\n",
      " [  8.15213298e-06  -6.64530489e-06  -2.18814625e-06 ...,  -5.26396093e-07\n",
      "   -1.86035618e-06  -4.11194742e-06]\n",
      " ..., \n",
      " [  6.42683017e-06  -5.23933795e-06  -1.72477007e-06 ...,  -4.14259745e-07\n",
      "   -1.46579077e-06  -3.23985637e-06]\n",
      " [ -1.68190072e-05   1.36974477e-05   4.52261520e-06 ...,   1.10779138e-06\n",
      "    3.86323291e-06   8.53873280e-06]\n",
      " [ -3.43850729e-06   2.79598589e-06   9.27391852e-07 ...,   2.33884450e-07\n",
      "    7.98332621e-07   1.76445485e-06]]\n",
      "<NDArray 256x256 @cpu(0)>\n",
      "\n",
      "[ -1.64410821e-03   1.33894407e-03   4.42113756e-04  -1.13993115e-03\n",
      "   1.03177573e-03  -1.02017788e-04  -3.67399130e-04  -8.66892980e-04\n",
      "  -7.33765657e-04  -8.68687057e-04  -4.53143875e-04   8.88161521e-05\n",
      "  -9.18888836e-04  -5.91337855e-04   2.67634423e-05  -2.16364191e-04\n",
      "   1.43871905e-04   3.68843263e-04  -5.52637910e-04   2.48545007e-07\n",
      "  -5.45794377e-04  -1.54336914e-03   6.64946798e-04   7.97115732e-04\n",
      "   5.30003053e-05  -1.85674973e-04  -8.48408265e-04  -8.85005400e-04\n",
      "  -5.76881692e-04   9.35219927e-04   4.96628694e-04   5.02974493e-04\n",
      "  -7.86968216e-04  -1.86670368e-04  -1.33317779e-03  -2.38707085e-04\n",
      "   7.57295114e-04   6.08307426e-04  -2.39145957e-04   9.77027463e-04\n",
      "  -3.73155228e-04  -4.79585171e-04  -2.37360364e-05  -1.05085294e-03\n",
      "  -4.68961225e-04  -4.07387182e-04  -8.65882728e-04  -2.05087184e-04\n",
      "   7.50235398e-04  -2.94187776e-04  -2.31930215e-04   7.47261452e-04\n",
      "   7.12379580e-04  -6.03668799e-04  -4.26394719e-04  -8.57334991e-04\n",
      "   1.23069901e-03  -4.88508551e-04   1.18657923e-03  -1.15908950e-03\n",
      "   1.07657118e-03  -1.49534200e-03   1.19935872e-03   4.23862453e-04\n",
      "  -1.13009848e-03   8.93916120e-04   3.71815950e-05  -5.85579721e-04\n",
      "  -2.61461071e-04   6.35493838e-04   9.28620400e-04   7.60897005e-04\n",
      "   1.30606198e-03   1.04405324e-03   6.86382584e-04   6.78702781e-04\n",
      "   6.14714401e-04   9.81263467e-04  -6.25753310e-04  -3.55321041e-04\n",
      "   3.11864569e-04   6.28124340e-04  -5.81123051e-04  -7.01109297e-04\n",
      "   4.67571546e-04   2.45015806e-04  -4.11714223e-04   7.29893392e-04\n",
      "   2.54503975e-04   8.10665369e-04  -4.24785656e-04  -7.45130063e-04\n",
      "   1.00088166e-03   1.26969488e-03   4.72597225e-04  -4.00212070e-04\n",
      "  -1.14525855e-03  -1.08261323e-04  -8.08849640e-04  -6.61921571e-04\n",
      "   2.93272722e-04   4.06795007e-04   5.69793163e-04  -1.21294206e-03\n",
      "  -1.18144718e-03  -5.73840749e-04  -4.93948828e-05   4.34938411e-04\n",
      "   1.15850256e-04  -5.01864648e-04  -9.14726043e-05  -1.97173940e-04\n",
      "   1.37789757e-03  -1.79011491e-04  -2.75890925e-04  -5.36245207e-05\n",
      "  -3.02834000e-04  -9.38887242e-05   8.08108831e-04   4.97970788e-04\n",
      "   4.99725284e-04  -5.58849017e-04  -4.91903920e-04  -2.99191452e-05\n",
      "  -9.70301335e-05  -1.50599529e-03   1.55515224e-03   7.52339984e-05\n",
      "  -4.73385298e-04   1.24025159e-04   1.61424498e-06  -1.05191699e-04\n",
      "   5.23619761e-04   8.36059276e-04  -3.65821528e-04  -5.89622883e-04\n",
      "  -3.66795080e-04   8.56200175e-04  -5.27887787e-05  -1.30544053e-04\n",
      "  -8.43098605e-05   5.34832827e-04  -2.83472560e-04   4.66709200e-04\n",
      "   1.73186127e-04  -1.47276776e-04   7.85117038e-04  -7.70252882e-05\n",
      "   3.74347146e-04  -9.90358065e-04   6.75125746e-04  -8.22021451e-04\n",
      "  -6.81397913e-04  -3.15243436e-04  -1.11276808e-03   8.17593362e-04\n",
      "   3.52514529e-04  -2.41767615e-04   2.28093093e-04  -8.00258247e-04\n",
      "  -8.82427616e-04   4.78724469e-05   5.75171376e-04  -5.84469817e-04\n",
      "  -1.49611174e-03   4.48447186e-04  -3.24658671e-04   5.90700656e-04\n",
      "  -4.78308037e-04   3.88511573e-04   2.28382942e-05   1.22361269e-03\n",
      "   9.63064609e-04  -2.33495550e-04  -5.27482945e-04  -8.81855725e-04\n",
      "   4.86252917e-04  -6.91638619e-04  -5.11564031e-05   1.27075496e-03\n",
      "  -1.00892631e-03  -2.29698111e-04  -6.21058047e-04  -1.69068153e-04\n",
      "  -5.13223167e-05  -1.37274165e-03  -2.45994015e-04  -3.04000423e-04\n",
      "   3.88472690e-04   1.53788447e-03  -9.96938441e-04   9.08682239e-04\n",
      "   9.49570269e-04   1.34632923e-03  -2.79788190e-04   5.66254777e-04\n",
      "  -5.74970734e-04   6.68400899e-04  -2.11241859e-04  -8.82506545e-04\n",
      "   5.60749730e-04  -1.63747201e-04  -6.82419850e-05  -6.62819730e-05\n",
      "  -3.42590123e-04  -3.22977867e-04  -1.10216299e-03  -5.18960587e-04\n",
      "  -4.51504457e-04   3.78913304e-04  -3.71217066e-05  -7.25765713e-04\n",
      "  -1.47295266e-03   3.40460276e-04  -4.72276355e-04  -1.57416347e-04\n",
      "  -5.20310481e-04   2.86296214e-04   2.63423775e-04  -3.44643850e-05\n",
      "   4.49374842e-04   2.97923369e-04  -9.48279994e-05   2.86929899e-05\n",
      "   2.72307923e-04  -1.77883299e-03   1.42298682e-04   1.39892870e-03\n",
      "   5.04387834e-04   7.34898320e-04  -5.84853115e-04   1.09852944e-03\n",
      "  -7.38694158e-04   5.95887890e-04   6.44658401e-04   9.39410471e-04\n",
      "  -3.71252274e-04   1.32030918e-05  -7.52664462e-04   3.10963405e-05\n",
      "  -2.28029967e-04  -1.60192649e-04   3.26257665e-04   5.87753893e-04\n",
      "   1.64135548e-04   2.89226096e-04   9.10582836e-04  -9.28321446e-04\n",
      "  -4.59301198e-04  -4.93559637e-04  -1.01051398e-03  -1.60114883e-04\n",
      "   1.38822116e-03   1.08328233e-04   3.77686694e-04   8.34783597e-04]\n",
      "<NDArray 256 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(params)):\n",
    "    print params[i].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('pred text: ', '                                                                                                                                                                               ')\n",
      "('cumulative loss: ', 0.032635350227355954)\n",
      "('pred text: ', 'q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q')\n",
      "('cumulative loss: ', 3.3107369685173036)\n",
      "('pred text: ', 'n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n')\n",
      "('cumulative loss: ', 3.2140099596977234)\n",
      "('pred text: ', 'sasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasasas')\n",
      "('cumulative loss: ', 3.1561190485954285)\n",
      "('pred text: ', 'e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e')\n",
      "('cumulative loss: ', 3.1052611112594604)\n",
      "('pred text: ', 'ejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejejej')\n",
      "('cumulative loss: ', 3.0682409548759462)\n",
      "('pred text: ', 'i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i ')\n",
      "('cumulative loss: ', 3.0268064880371095)\n",
      "('pred text: ', ' n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n ')\n",
      "('cumulative loss: ', 2.9969953727722167)\n",
      "('pred text: ', 'q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q ')\n",
      "('cumulative loss: ', 2.969683015346527)\n",
      "('pred text: ', ' n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n ')\n",
      "('cumulative loss: ', 2.9429608225822448)\n",
      "('pred text: ', '                                                                                                                                                                         ')\n",
      "('cumulative loss: ', 2.9294692611694337)\n",
      "('pred text: ', '                                                                                                      ')\n",
      "('cumulative loss: ', 2.9076782298088073)\n",
      "('pred text: ', '                                                                                                                                                 ')\n",
      "('cumulative loss: ', 2.8955837512016296)\n",
      "('pred text: ', ' e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e ')\n",
      "('cumulative loss: ', 2.888536424636841)\n",
      "('pred text: ', '                                                                                                                                                        ')\n",
      "('cumulative loss: ', 2.8637906837463381)\n",
      "('pred text: ', '                                                                                                                    ')\n",
      "('cumulative loss: ', 2.8543481183052064)\n",
      "('pred text: ', '                                                                                                                                                                         ')\n",
      "('cumulative loss: ', 2.8574484038352965)\n",
      "('pred text: ', ' e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e ')\n",
      "('cumulative loss: ', 2.8484254932403563)\n",
      "('pred text: ', '                                                                                                                                                       ')\n",
      "('cumulative loss: ', 2.8369316387176515)\n",
      "('pred text: ', '                                                                                                                          ')\n",
      "('cumulative loss: ', 2.8236286187171937)\n",
      "('pred text: ', ' e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e')\n",
      "('cumulative loss: ', 2.8303010535240172)\n",
      "('pred text: ', '                                                                                                                                  ')\n",
      "('cumulative loss: ', 2.8163860535621641)\n",
      "('pred text: ', '                                                                      ')\n",
      "('cumulative loss: ', 2.819627809524536)\n",
      "('pred text: ', '                                                                                                                                                                          ')\n",
      "('cumulative loss: ', 2.8150377178192141)\n",
      "('pred text: ', '                                                                                                                                ')\n",
      "('cumulative loss: ', 2.8152203106880189)\n",
      "('pred text: ', '                                                                                                                                           ')\n",
      "('cumulative loss: ', 2.8107533049583435)\n",
      "('pred text: ', '                                                                                                                                         ')\n",
      "('cumulative loss: ', 2.8145328092575075)\n",
      "('pred text: ', '                                                                                                                                   ')\n",
      "('cumulative loss: ', 2.8100376868247987)\n",
      "('pred text: ', '                                                                                                                                                                                                      ')\n",
      "('cumulative loss: ', 2.8154242777824403)\n",
      "('pred text: ', '                                                                                                                                         ')\n",
      "('cumulative loss: ', 2.7993503856658934)\n",
      "('pred text: ', '                                                                                                                ')\n",
      "('cumulative loss: ', 2.8074783611297609)\n",
      "('pred text: ', '                                                                                                                                                            ')\n",
      "('cumulative loss: ', 2.8125088882446287)\n",
      "('pred text: ', '                                                                                                                        ')\n",
      "('cumulative loss: ', 2.8054976511001586)\n",
      "('pred text: ', '                                                                                       ')\n",
      "('cumulative loss: ', 2.7903503227233886)\n",
      "('pred text: ', '                                                                                                             ')\n",
      "('cumulative loss: ', 2.812976155281067)\n",
      "('pred text: ', '                                                                                                                              ')\n",
      "('cumulative loss: ', 2.8099198269844057)\n",
      "('pred text: ', '                                                                                                                           ')\n",
      "('cumulative loss: ', 2.7987797808647157)\n",
      "('pred text: ', '                                                                                                                                                                                                                                                                                     ')\n",
      "('cumulative loss: ', 2.7904245448112488)\n",
      "('pred text: ', '                                                                                                                 ')\n",
      "('cumulative loss: ', 2.8001067495346068)\n",
      "('pred text: ', ' e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e')\n",
      "('cumulative loss: ', 2.7933456230163576)\n",
      "('pred text: ', '                                                                                                                ')\n",
      "('cumulative loss: ', 2.8061529445648192)\n",
      "('pred text: ', '                                                                                                                              ')\n",
      "('cumulative loss: ', 2.8009961104393004)\n",
      "('pred text: ', 'e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e ')\n",
      "('cumulative loss: ', 2.7983677744865418)\n",
      "('pred text: ', '                                                                                                                                        ')\n",
      "('cumulative loss: ', 2.8140004062652588)\n",
      "('pred text: ', '                                                                                                                                         ')\n",
      "('cumulative loss: ', 2.7906132745742798)\n",
      "('pred text: ', '                                                                                                 ')\n",
      "('cumulative loss: ', 2.8012346982955934)\n",
      "('pred text: ', '                                                                                                                                                                    ')\n",
      "('cumulative loss: ', 2.7910648870468138)\n",
      "('pred text: ', ' e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e ')\n",
      "('cumulative loss: ', 2.8035052704811094)\n",
      "('pred text: ', '                                                                                                                                                                                                  ')\n",
      "('cumulative loss: ', 2.7980655169487001)\n",
      "('pred text: ', '                                                                                                                                                       ')\n",
      "('cumulative loss: ', 2.7885730004310609)\n",
      "('pred text: ', '                                         ')\n",
      "('cumulative loss: ', 2.8042045927047727)\n",
      "('pred text: ', '                                                                                                              ')\n",
      "('cumulative loss: ', 2.8002295732498168)\n",
      "('pred text: ', '                                                                                                                                ')\n",
      "('cumulative loss: ', 2.8054358530044556)\n",
      "('pred text: ', 'e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e ')\n",
      "('cumulative loss: ', 2.7956782793998718)\n",
      "('pred text: ', '                                                                                                                                                      ')\n",
      "('cumulative loss: ', 2.7997471189498899)\n",
      "('pred text: ', '                                                                                                                                                                            ')\n",
      "('cumulative loss: ', 2.7914834904670713)\n",
      "('pred text: ', '                                                                                                                                                                                          ')\n",
      "('cumulative loss: ', 2.7958418273925782)\n",
      "('pred text: ', '                                                                                                                                                                       ')\n",
      "('cumulative loss: ', 2.793727788925171)\n",
      "('pred text: ', '                                                                                                                  ')\n",
      "('cumulative loss: ', 2.7857659292221069)\n",
      "('pred text: ', '                                                                                                                                              ')\n",
      "('cumulative loss: ', 2.8009225034713747)\n",
      "('pred text: ', '                                                                                                                       ')\n",
      "('cumulative loss: ', 2.7905264925956725)\n",
      "('pred text: ', '                                                                                                                                        ')\n",
      "('cumulative loss: ', 2.7889732718467712)\n",
      "('pred text: ', '                                                                                                                                    ')\n",
      "('cumulative loss: ', 2.8053289794921876)\n",
      "('pred text: ', '                                                                      ')\n",
      "('cumulative loss: ', 2.8123585820198058)\n",
      "('pred text: ', '                                                                                                                                                          ')\n",
      "('cumulative loss: ', 2.7911977863311765)\n",
      "('pred text: ', '                                                                                                                                                                                         ')\n",
      "('cumulative loss: ', 2.7832502388954161)\n",
      "('pred text: ', '                                                                                                                                                        ')\n",
      "('cumulative loss: ', 2.7965887045860289)\n",
      "('pred text: ', '                                                                                                                                                                        ')\n",
      "('cumulative loss: ', 2.8064070057868959)\n",
      "('pred text: ', '                                                                                                                                                                                                                                     ')\n",
      "('cumulative loss: ', 2.7944321584701539)\n",
      "('pred text: ', '                                                                                                                                                              ')\n",
      "('cumulative loss: ', 2.8014625763893126)\n",
      "('pred text: ', '                                                                                                                                                          ')\n",
      "('cumulative loss: ', 2.799009666442871)\n",
      "('pred text: ', '                                                                                                                   ')\n",
      "('cumulative loss: ', 2.7929136300086976)\n",
      "('pred text: ', '                                                                                                                                                                                                   ')\n",
      "('cumulative loss: ', 2.7947698640823364)\n",
      "('pred text: ', '                                                                                                                                                                           ')\n",
      "('cumulative loss: ', 2.7840244197845458)\n",
      "('pred text: ', '                                                                                                          ')\n",
      "('cumulative loss: ', 2.7938940358161926)\n",
      "('pred text: ', '                                                                                                                       ')\n",
      "('cumulative loss: ', 2.7840076994895937)\n",
      "('pred text: ', '                                                                                                                             ')\n",
      "('cumulative loss: ', 2.7972975230216979)\n",
      "('pred text: ', '                                                                                                                    ')\n",
      "('cumulative loss: ', 2.7949140739440916)\n",
      "('pred text: ', '                                                                                                            ')\n",
      "('cumulative loss: ', 2.7843498277664183)\n",
      "('pred text: ', '                                                                                                     ')\n",
      "('cumulative loss: ', 2.799069845676422)\n",
      "('pred text: ', '                                                                                                                               ')\n",
      "('cumulative loss: ', 2.7885060620307924)\n",
      "('pred text: ', '                                                                                                                                                                                                                                       ')\n",
      "('cumulative loss: ', 2.795906162261963)\n",
      "('pred text: ', '                                                                                                                                                     ')\n",
      "('cumulative loss: ', 2.7952443194389343)\n",
      "('pred text: ', '                                                                                                                                 ')\n",
      "('cumulative loss: ', 2.7907563114166258)\n",
      "('pred text: ', '                                                                                                                     ')\n",
      "('cumulative loss: ', 2.7977237725257873)\n",
      "('pred text: ', '                                                                                                                           ')\n",
      "('cumulative loss: ', 2.7876796722412109)\n",
      "('pred text: ', '                                                                                                                        ')\n",
      "('cumulative loss: ', 2.7878665065765382)\n",
      "('pred text: ', '                                                                                                                                  ')\n",
      "('cumulative loss: ', 2.7940784072875977)\n",
      "('pred text: ', '                                                                                                                                     ')\n",
      "('cumulative loss: ', 2.7932916784286501)\n",
      "('pred text: ', '                                                                                             ')\n",
      "('cumulative loss: ', 2.8003357410430909)\n",
      "('pred text: ', '                                                                                                                                                                                                         ')\n",
      "('cumulative loss: ', 2.8019909811019899)\n",
      "('pred text: ', '                                                                                                                                                                                          ')\n",
      "('cumulative loss: ', 2.7899930572509763)\n",
      "('pred text: ', '                                                                                                                                                                                  ')\n",
      "('cumulative loss: ', 2.7927759456634522)\n",
      "('pred text: ', '                                                                                                                                                           ')\n",
      "('cumulative loss: ', 2.8021163749694824)\n",
      "('pred text: ', '                                                                                                                           ')\n",
      "('cumulative loss: ', 2.791978130340576)\n",
      "('pred text: ', '                                                                                                                                                                                                                                                                                                                  ')\n",
      "('cumulative loss: ', 2.7949108862876892)\n",
      "('pred text: ', '                                                                                                                                                    ')\n",
      "('cumulative loss: ', 2.7934840178489684)\n",
      "('pred text: ', '                                                                                                                                                                                                                  ')\n",
      "('cumulative loss: ', 2.8016576194763183)\n",
      "('pred text: ', '                                                                                                                         ')\n",
      "('cumulative loss: ', 2.794004774093628)\n",
      "('pred text: ', '                                                                         ')\n",
      "('cumulative loss: ', 2.7889910411834715)\n",
      "('pred text: ', '                                                                                                                                                                   ')\n",
      "('cumulative loss: ', 2.7822175455093383)\n",
      "('pred text: ', '                                                                                                                                                                                 ')\n",
      "('cumulative loss: ', 2.7929269909858703)\n",
      "('pred text: ', '                                                                                                        ')\n",
      "('cumulative loss: ', 2.8028607678413393)\n",
      "('pred text: ', '                                                                                                                                         ')\n",
      "('cumulative loss: ', 2.8000131130218504)\n",
      "('pred text: ', '                                                                                                                                                                                                                ')\n",
      "('cumulative loss: ', 2.7923780035972596)\n",
      "('pred text: ', '                                                                                                                                                                                                         ')\n",
      "('cumulative loss: ', 2.7906195020675657)\n",
      "('pred text: ', 'e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e')\n",
      "('cumulative loss: ', 2.8094085669517517)\n",
      "('pred text: ', '                                                                                                                  ')\n",
      "('cumulative loss: ', 2.8024419808387755)\n",
      "('pred text: ', '                                                                                                   ')\n",
      "('cumulative loss: ', 2.8034707784652708)\n",
      "('pred text: ', '                                                                                                                                                     ')\n",
      "('cumulative loss: ', 2.7801368165016176)\n",
      "('pred text: ', '                                                                                                                                                   ')\n",
      "('cumulative loss: ', 2.8098427820205689)\n",
      "('pred text: ', '                                                                                              ')\n",
      "('cumulative loss: ', 2.7928977227210998)\n",
      "('pred text: ', '                                                                                                                                                                     ')\n",
      "('cumulative loss: ', 2.7887437868118288)\n",
      "('pred text: ', '                                                                                                                           ')\n",
      "('cumulative loss: ', 2.7920011234283448)\n",
      "('pred text: ', '                                                                                                                                                                             ')\n",
      "('cumulative loss: ', 2.790297713279724)\n",
      "('pred text: ', '                                                                                                                                                                                                                                      ')\n",
      "('cumulative loss: ', 2.7748006439208983)\n",
      "('pred text: ', 'e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e')\n",
      "('cumulative loss: ', 2.7986634016036986)\n",
      "('pred text: ', '                                                                                                                                                          ')\n",
      "('cumulative loss: ', 2.7782373213768006)\n",
      "('pred text: ', '                                                                                                                                          ')\n",
      "('cumulative loss: ', 2.7975419354438782)\n",
      "('pred text: ', '                                                                                                                                            ')\n",
      "('cumulative loss: ', 2.7982160925865172)\n",
      "('pred text: ', '                                                                                                                                            ')\n",
      "('cumulative loss: ', 2.796715507507324)\n",
      "('pred text: ', '                                                                                                                     ')\n",
      "('cumulative loss: ', 2.7901127672195436)\n",
      "('pred text: ', ' e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e ')\n",
      "('cumulative loss: ', 2.7857950305938721)\n",
      "('pred text: ', '                                                                                                                                           ')\n",
      "('cumulative loss: ', 2.7830362319946289)\n",
      "('pred text: ', '                                                                                                                                                                                                         ')\n",
      "('cumulative loss: ', 2.7873466920852663)\n",
      "('pred text: ', '                                                                                                          ')\n",
      "('cumulative loss: ', 2.7914016246795654)\n",
      "('pred text: ', '                                                                                     ')\n",
      "('cumulative loss: ', 2.7980067300796509)\n",
      "('pred text: ', '                                                                                                                                       ')\n",
      "('cumulative loss: ', 2.7854975247383118)\n",
      "('pred text: ', '                                                                                                                       ')\n",
      "('cumulative loss: ', 2.7917637372016908)\n",
      "('pred text: ', '                                                                                        ')\n",
      "('cumulative loss: ', 2.7901583218574526)\n",
      "('pred text: ', '                                                                                                                   ')\n",
      "('cumulative loss: ', 2.7937067914009095)\n",
      "('pred text: ', '                                                                                                                                      ')\n",
      "('cumulative loss: ', 2.7892458462715148)\n",
      "('pred text: ', '                                                                                                                                      ')\n",
      "('cumulative loss: ', 2.8016203665733337)\n",
      "('pred text: ', '                                                                                                                                                                                      ')\n",
      "('cumulative loss: ', 2.784873650074005)\n",
      "('pred text: ', '                                                                                                                                          ')\n",
      "('cumulative loss: ', 2.7869727230072021)\n",
      "('pred text: ', '                                                                                                                                                                                                               ')\n",
      "('cumulative loss: ', 2.7929580998420716)\n",
      "('pred text: ', ' e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e ')\n",
      "('cumulative loss: ', 2.8062060284614563)\n",
      "('pred text: ', '                                                                                                                                                ')\n",
      "('cumulative loss: ', 2.7948838400840761)\n",
      "('pred text: ', '                                                                                                                                                                                                       ')\n",
      "('cumulative loss: ', 2.7900494480133058)\n",
      "('pred text: ', '                                                                                                                                                                                ')\n",
      "('cumulative loss: ', 2.7905059576034548)\n",
      "('pred text: ', '                                                                                                                                                        ')\n",
      "('cumulative loss: ', 2.8006702780723574)\n",
      "('pred text: ', '                                                                                                                                                                                                   ')\n",
      "('cumulative loss: ', 2.8012769913673399)\n",
      "('pred text: ', '                                                                     ')\n",
      "('cumulative loss: ', 2.7817336583137511)\n",
      "('pred text: ', '                                                                                                                                                                           ')\n",
      "('cumulative loss: ', 2.8014000654220581)\n",
      "('pred text: ', '                                                                                                                  ')\n",
      "('cumulative loss: ', 2.792939682006836)\n",
      "('pred text: ', '                                                                                                                                                                     ')\n",
      "('cumulative loss: ', 2.7784392595291139)\n",
      "('pred text: ', '                                                                                                                                             ')\n",
      "('cumulative loss: ', 2.7911830663681032)\n",
      "('pred text: ', '                                                                                                        ')\n",
      "('cumulative loss: ', 2.8015553092956544)\n",
      "('pred text: ', '                                                                                                                                                                                                              ')\n",
      "('cumulative loss: ', 2.784994900226593)\n",
      "('pred text: ', '                                                                                                                                                                         ')\n",
      "('cumulative loss: ', 2.7954200458526612)\n",
      "('pred text: ', '                                                                                                    ')\n",
      "('cumulative loss: ', 2.7905048155784606)\n",
      "('pred text: ', '                                                                                                                                                                                                                             ')\n",
      "('cumulative loss: ', 2.7971246886253356)\n",
      "('pred text: ', '                                                                                                                   ')\n",
      "('cumulative loss: ', 2.7958102774620057)\n",
      "('pred text: ', '                                                     ')\n",
      "('cumulative loss: ', 2.796939775943756)\n",
      "('pred text: ', '                                                                                              ')\n",
      "('cumulative loss: ', 2.7929996061325073)\n",
      "('pred text: ', '                                                                                                                                           ')\n",
      "('cumulative loss: ', 2.7883205533027651)\n",
      "('pred text: ', '                                                                                                                        ')\n",
      "('cumulative loss: ', 2.7884334516525269)\n",
      "('pred text: ', '                                                                                                                 ')\n",
      "('cumulative loss: ', 2.7887910676002501)\n",
      "('pred text: ', '                                                                                                                     ')\n",
      "('cumulative loss: ', 2.7956838297843931)\n",
      "('pred text: ', '                                                                                                                                           ')\n",
      "('cumulative loss: ', 2.7990259647369387)\n",
      "('pred text: ', '                                                                                                                                                          ')\n",
      "('cumulative loss: ', 2.7878141045570373)\n",
      "('pred text: ', '                                                                                                ')\n",
      "('cumulative loss: ', 2.7934715008735655)\n",
      "('pred text: ', '                                                                                             ')\n",
      "('cumulative loss: ', 2.7785228967666624)\n",
      "('pred text: ', '                                                                                                                                                                                                                                   ')\n",
      "('cumulative loss: ', 2.7931029701232912)\n",
      "('pred text: ', '                                                                                                                                                                                                          ')\n",
      "('cumulative loss: ', 2.8008230662345888)\n",
      "('pred text: ', '                                                                                                                                                                    ')\n",
      "('cumulative loss: ', 2.8044875764846804)\n",
      "('pred text: ', '                                                                                                                            ')\n",
      "('cumulative loss: ', 2.7945311069488525)\n",
      "('pred text: ', '                                                                                                                                   ')\n",
      "('cumulative loss: ', 2.7882505464553833)\n",
      "('pred text: ', '                                                                                                                                                                                           ')\n",
      "('cumulative loss: ', 2.8030280780792238)\n",
      "('pred text: ', '                                                                                                                                                ')\n",
      "('cumulative loss: ', 2.7894978404045103)\n",
      "('pred text: ', '                                                                                                                                          ')\n",
      "('cumulative loss: ', 2.7958764028549195)\n",
      "('pred text: ', '                                                                                                                                       ')\n",
      "('cumulative loss: ', 2.8000188183784487)\n",
      "('pred text: ', '                                                                                                                                                                        ')\n",
      "('cumulative loss: ', 2.7808694601058961)\n",
      "('pred text: ', '                                                                                                                                                                                                                                                                                                                        ')\n",
      "('cumulative loss: ', 2.7962336540222168)\n",
      "('pred text: ', '                                                                                                  ')\n",
      "('cumulative loss: ', 2.7855764770507814)\n",
      "('pred text: ', '                                                                                                                                                ')\n",
      "('cumulative loss: ', 2.807697284221649)\n",
      "('pred text: ', '                                                                                                                                                                                                                 ')\n",
      "('cumulative loss: ', 2.7885968708992004)\n",
      "('pred text: ', '                                                                                                                                                                            ')\n",
      "('cumulative loss: ', 2.7829821729660034)\n",
      "('pred text: ', '                                                                                                                                                         ')\n",
      "('cumulative loss: ', 2.7968002581596374)\n",
      "('pred text: ', '                                                                                                                                               ')\n",
      "('cumulative loss: ', 2.7772093319892885)\n",
      "('pred text: ', '                                                                                                     ')\n",
      "('cumulative loss: ', 2.7760835456848145)\n",
      "('pred text: ', '                                                                                                                                                                       ')\n",
      "('cumulative loss: ', 2.7888312244415285)\n",
      "('pred text: ', '                                                                                                               ')\n",
      "('cumulative loss: ', 2.7780514097213747)\n",
      "('pred text: ', '                                                                                                                              ')\n",
      "('cumulative loss: ', 2.7967434453964235)\n",
      "('pred text: ', '                                                                                                                                                                                                                                            ')\n",
      "('cumulative loss: ', 2.7928390908241272)\n",
      "('pred text: ', '                                                                                                                                                        ')\n",
      "('cumulative loss: ', 2.8035688638687133)\n",
      "('pred text: ', '                                                                                                                                                                      ')\n",
      "('cumulative loss: ', 2.7984723758697512)\n",
      "('pred text: ', '                                                                                                                                                 ')\n",
      "('cumulative loss: ', 2.7845661354064943)\n",
      "('pred text: ', '                                                                                                                                                     ')\n",
      "('cumulative loss: ', 2.7923856329917909)\n",
      "('pred text: ', '                                                                                                                                   ')\n",
      "('cumulative loss: ', 2.7950012588500979)\n",
      "('pred text: ', '                                                                                                                                                                                                                                                   ')\n",
      "('cumulative loss: ', 2.7846449708938597)\n",
      "('pred text: ', '                                                                                                                                                                          ')\n",
      "('cumulative loss: ', 2.8010021567344667)\n",
      "('pred text: ', '                                                                                                                           ')\n",
      "('cumulative loss: ', 2.7974910831451414)\n",
      "('pred text: ', '                                                                                                                            ')\n",
      "('cumulative loss: ', 2.8069741320610047)\n",
      "('pred text: ', '                                                                                                                                          ')\n",
      "('cumulative loss: ', 2.7866090726852417)\n",
      "('pred text: ', '                                                                                                               ')\n",
      "('cumulative loss: ', 2.7994449758529663)\n",
      "('pred text: ', '                                                                                                                                                               ')\n",
      "('cumulative loss: ', 2.7952734494209288)\n",
      "('pred text: ', 'e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e ')\n",
      "('cumulative loss: ', 2.7867878842353822)\n",
      "('pred text: ', '                                                                                                                                                                                       ')\n",
      "('cumulative loss: ', 2.7891117358207702)\n",
      "('pred text: ', '                                                                                                                                                     ')\n",
      "('cumulative loss: ', 2.7869154405593872)\n",
      "('pred text: ', '                                                                                                                                                                   ')\n",
      "('cumulative loss: ', 2.7806565260887144)\n",
      "('pred text: ', '                                                                                                                                                        ')\n",
      "('cumulative loss: ', 2.7993389391899108)\n",
      "('pred text: ', '                                                                  ')\n",
      "('cumulative loss: ', 2.7856836295127869)\n",
      "('pred text: ', '                                                                                                                      ')\n",
      "('cumulative loss: ', 2.7934134578704835)\n",
      "('pred text: ', '                                                                                                                                                                               ')\n",
      "('cumulative loss: ', 2.7982092881202698)\n",
      "('pred text: ', '                                                                                                                                                                 ')\n",
      "('cumulative loss: ', 2.79806932926178)\n",
      "('pred text: ', '                                                                                                       ')\n",
      "('cumulative loss: ', 2.7852545690536501)\n",
      "('pred text: ', '                                                                                                                             ')\n",
      "('cumulative loss: ', 2.792891733646393)\n",
      "('pred text: ', '                                                                                                                                                                                ')\n",
      "('cumulative loss: ', 2.7917121696472167)\n",
      "('pred text: ', '                                                                                                                                                                                 ')\n",
      "('cumulative loss: ', 2.7951047945022585)\n",
      "('pred text: ', '                                                                                                                                               ')\n",
      "('cumulative loss: ', 2.7964210152626037)\n",
      "('pred text: ', '                                                                                       ')\n",
      "('cumulative loss: ', 2.7996592450141908)\n",
      "('pred text: ', 'e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e ')\n",
      "('cumulative loss: ', 2.7993974304199218)\n",
      "('pred text: ', '                                                                                                                             ')\n",
      "('cumulative loss: ', 2.7896932005882262)\n",
      "('pred text: ', '                                                                                                                           ')\n",
      "('cumulative loss: ', 2.7949650049209596)\n",
      "('pred text: ', '                                                                                                                                         ')\n",
      "('cumulative loss: ', 2.7937025117874144)\n",
      "('pred text: ', '                                                                                                                                           ')\n",
      "('cumulative loss: ', 2.7768733668327332)\n",
      "('pred text: ', ' e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e')\n",
      "('cumulative loss: ', 2.7975877928733826)\n",
      "('pred text: ', '                                                                                                                                                           ')\n",
      "('cumulative loss: ', 2.7917148423194886)\n",
      "('pred text: ', '                                                                                             ')\n",
      "('cumulative loss: ', 2.8074158000946046)\n",
      "('pred text: ', '                                                                                                           ')\n",
      "('cumulative loss: ', 2.7955354046821594)\n",
      "('pred text: ', '                                                                                                                          ')\n",
      "('cumulative loss: ', 2.7862837314605713)\n",
      "('pred text: ', '                                                                       ')\n",
      "('cumulative loss: ', 2.7916229295730592)\n",
      "('pred text: ', '                                                                             ')\n",
      "('cumulative loss: ', 2.7936252140998841)\n",
      "('pred text: ', '                                                                                               ')\n",
      "('cumulative loss: ', 2.78099600315094)\n",
      "('pred text: ', '                                                                                                                                                                                                  ')\n",
      "('cumulative loss: ', 2.7873241186141966)\n",
      "('pred text: ', '                                                                                                     ')\n",
      "('cumulative loss: ', 2.7909795737266538)\n",
      "('pred text: ', '                                                                                                                                                     ')\n",
      "('cumulative loss: ', 2.797997488975525)\n",
      "('pred text: ', '                                                                                                                                           ')\n",
      "('cumulative loss: ', 2.7933104228973389)\n",
      "('pred text: ', '                                                                                                   ')\n",
      "('cumulative loss: ', 2.7982434248924255)\n",
      "('pred text: ', '                                                                                                                                          ')\n",
      "('cumulative loss: ', 2.7918965005874634)\n",
      "('pred text: ', '                                                                                                                                                                        ')\n",
      "('cumulative loss: ', 2.7830855989456178)\n",
      "('pred text: ', '                                                                                                                                                                                            ')\n",
      "('cumulative loss: ', 2.7869790148735047)\n",
      "('pred text: ', '                                                                                                                                                     ')\n",
      "('cumulative loss: ', 2.7970384311676026)\n",
      "('pred text: ', '                                           ')\n",
      "('cumulative loss: ', 2.7771483898162841)\n",
      "('pred text: ', '                                                                                                           ')\n",
      "('cumulative loss: ', 2.7989575099945068)\n",
      "('pred text: ', '                                                                                                                                                  ')\n",
      "('cumulative loss: ', 2.7786459612846373)\n",
      "('pred text: ', '                                                                                                                   ')\n",
      "('cumulative loss: ', 2.7863714909553527)\n",
      "('pred text: ', '                                                                                                                       ')\n",
      "('cumulative loss: ', 2.796152594089508)\n",
      "('pred text: ', '                                                                                                                              ')\n",
      "('cumulative loss: ', 2.7770217537879942)\n",
      "('pred text: ', '                                                                                                                                ')\n",
      "('cumulative loss: ', 2.7875588941574097)\n",
      "('pred text: ', '                                                                                                                                            ')\n",
      "('cumulative loss: ', 2.8076432847976687)\n",
      "('pred text: ', '                                                                                                                                     ')\n",
      "('cumulative loss: ', 2.7908854675292969)\n",
      "('pred text: ', '                                                                                                                                                   ')\n",
      "('cumulative loss: ', 2.800137836933136)\n",
      "('pred text: ', '                                                                                                                    ')\n",
      "('cumulative loss: ', 2.7835689425468444)\n",
      "('pred text: ', '                                                                                                                         ')\n",
      "('cumulative loss: ', 2.7846385693550109)\n",
      "('pred text: ', '                                                                                             ')\n",
      "('cumulative loss: ', 2.8041214179992675)\n",
      "('pred text: ', '                                                                                                                                                                          ')\n",
      "('cumulative loss: ', 2.8005723786354064)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-370-ef75316d3e14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m#graphing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0msum_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mcum_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msum_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mx_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/davis/anaconda2/lib/python2.7/site-packages/mxnet/ndarray/ndarray.pyc\u001b[0m in \u001b[0;36masscalar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1809\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1810\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The current array is not a scalar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1811\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/davis/anaconda2/lib/python2.7/site-packages/mxnet/ndarray/ndarray.pyc\u001b[0m in \u001b[0;36masnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1791\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1793\u001b[0;31m             ctypes.c_size_t(data.size)))\n\u001b[0m\u001b[1;32m   1794\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi']= 120\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss_tracker = []\n",
    "counter = 0\n",
    "vs, sqrs = setup_adam(params)\n",
    "for epoch in range(100):\n",
    "    cum_loss = 0\n",
    "    for i in range(len(data)):\n",
    "        \n",
    "        with autograd.record():\n",
    "            en = numerical_to_nd(data[i],translation_dict)\n",
    "            fr = numerical_to_nd(labels[i],translation_dict)\n",
    "            en = en.reshape((en.shape[1],en.shape[2],en.shape[3]))\n",
    "            fr = fr.reshape((fr.shape[1],fr.shape[2],fr.shape[3]))\n",
    "            \n",
    "            output_encoder_layer_0,hidden_encoder_layer_0=encoder(\n",
    "                en.shape[0], en, num_hidden, int(en.shape[2]), \n",
    "                nd.zeros(num_hidden),encoder_params)\n",
    "            \n",
    "            temp = nd.concat(*output_encoder_layer_0)\n",
    "            o_e = nd.reshape(temp,(temp.shape[1],1,temp.shape[0]))\n",
    "            \n",
    "            output_encoder_layer_1,hidden_encoder_layer_1=encoder(\n",
    "                o_e.shape[0], o_e, num_hidden, int(o_e.shape[2]), \n",
    "                hidden_encoder_layer_0,encoder_params_1)\n",
    "       \n",
    "            out_enc = list_to_nd_array(output_encoder_layer_1)\n",
    "        \n",
    "            output_decoder, hidden_state = decoder(\n",
    "                fr.shape[0],out_enc,nd.reshape(hidden_encoder_layer_1,(num_hidden)),\n",
    "                num_hidden,int(fr.shape[2]),decoder_params, att_params)\n",
    "            \n",
    "            loss = average_ce_loss(output_decoder, nd.reshape(fr,(fr.shape[0],fr.shape[2]))) \n",
    "\n",
    "        loss.backward()\n",
    "        counter += 1\n",
    "        adam(params, vs, sqrs, learning_rate, 1, counter)\n",
    "        \n",
    "        #graphing\n",
    "        sum_loss = nd.sum(loss)\n",
    "        cum_loss += sum_loss.asscalar()\n",
    "        x_axis = range(len(loss_tracker))\n",
    "        if(i%100==0):\n",
    "            \n",
    "            print(\"pred text: \",textify(list_to_nd_array_with_reshaping(output_decoder)))\n",
    "            print(\"cumulative loss: \", cum_loss/100)\n",
    "            cum_loss = 0\n",
    "            loss_tracker.append(cum_loss)\n",
    "    \n",
    "    plt.semilogy(x_axis, loss_tracker)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def setup_adam(params):\n",
    "    sqrs = []\n",
    "    vs = []\n",
    "    for param in params:\n",
    "        vs.append(param.zeros_like())\n",
    "        sqrs.append(param.zeros_like())\n",
    "    return vs, sqrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class attention_block(Block):\n",
    "    def __init__(self, decoder_state_size, encoder_state_size, attention_size, **kwargs):\n",
    "        super(attention_block, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.decoder_state_size = decoder_state_size\n",
    "            self.encoder_state_size = encoder_state_size\n",
    "            self.attention_size = attention_size\n",
    "            \n",
    "            self.W = self.params.get('W', init=mx.init.Xavier(magnitude=2.24), \n",
    "                                     shape=(self.attention_size,self.decoder_state_size))\n",
    "            self.V = self.params.get('V', init=mx.init.Xavier(magnitude=2.24), \n",
    "                                     shape=(self.attention_size,self.encoder_state_size))\n",
    "            self.w = self.params.get('w', init=mx.init.Xavier(magnitude=2.24), \n",
    "                                     shape=(1,self.attention_size))\n",
    "            self.b = self.params.get('b', shape=(self.attention_size,1))\n",
    "    \n",
    "    def forward(self, decoder_hidden, encoder_output):\n",
    "        with encoder_output.context:\n",
    "            decoder_temp = nd.dot(self.W,decoder_hidden)\n",
    "            encoder_temp = nd.dot(self.V,encoder_output)\n",
    "            net_temp = nd.reshape(decoder_temp,(decoder_temp.shape[0],1))+encoder_temp+self.b\n",
    "            return nd.dot(self.w,nd.tanh(net_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
       " [ 0.  0.  0. ...,  0.  0.  0.]\n",
       " [ 0.  0.  0. ...,  0.  0.  0.]\n",
       " ..., \n",
       " [ 0.  0.  0. ...,  0.  0.  0.]\n",
       " [ 0.  0.  0. ...,  0.  0.  0.]\n",
       " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
       "<NDArray 256x256 @cpu(0)>"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[17].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[  1.30422052e-03  -6.41440973e-03   5.10825589e-03 ...,  -1.34379510e-02\n",
       "    4.31262924e-05   9.32443980e-03]\n",
       " [  1.39874090e-02   1.74041204e-02   1.10777542e-02 ...,   6.40203105e-03\n",
       "    2.06707995e-02   7.28362380e-03]\n",
       " [  1.37236156e-03   5.07817464e-03   2.42010169e-02 ...,  -7.58874975e-03\n",
       "   -8.40481278e-03   8.14634562e-03]\n",
       " ..., \n",
       " [ -1.86159983e-02  -1.86261116e-03   3.53552550e-02 ...,  -1.22878852e-03\n",
       "    3.85040039e-04  -1.27779124e-02]\n",
       " [  1.55838989e-02  -1.56477792e-03  -1.03876069e-02 ...,  -6.73914840e-03\n",
       "    1.66862477e-02  -2.55577289e-03]\n",
       " [  1.31259812e-03   9.93658323e-03  -5.96137485e-03 ...,  -1.68684535e-02\n",
       "    1.60950851e-02  -2.09686020e-03]]\n",
       "<NDArray 256x256 @cpu(0)>"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet.gluon import nn, rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes exactly 5 arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-213-fae25bbca6bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m27\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBasicAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdense\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m27\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_units\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes exactly 5 arguments (1 given)"
     ]
    }
   ],
   "source": [
    "e = rnn.LSTM(256, 3, input_size=27)\n",
    "d = rnn.LSTM(256, 3, input_size = 256)\n",
    "\n",
    "dense = nn.Dense(27, in_units = 256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
